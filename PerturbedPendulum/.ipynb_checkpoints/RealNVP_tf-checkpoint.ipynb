{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PACKAGE IMPORTS ####\n",
    "\n",
    "# Run this cell first to import all required packages. Do not make any imports elsewhere in the notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "import random as rd\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points:  199999\n"
     ]
    }
   ],
   "source": [
    "file = open(\"x_train.txt\", \"r\")\n",
    "line_count = 0\n",
    "for line in file:\n",
    "    if line != \"\\n\":\n",
    "        line_count += 1\n",
    "file.close()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "read_x = open(\"x_train.txt\", \"r\")\n",
    "read_y = open(\"y_train.txt\", \"r\")\n",
    "#read_z = open(\"z_train.txt\", \"r\")\n",
    "\n",
    "for i in range(int(line_count)):\n",
    "\n",
    "    x.append([float(read_x.readline()), float(read_y.readline())])#, float(read_z.readline())])\n",
    "\n",
    "read_x.close()\n",
    "read_y.close()\n",
    "#read_z.close()\n",
    "\n",
    "x_train = tf.constant(x[:-1])\n",
    "y_train = tf.constant(x[1:])\n",
    "\n",
    "print(\"Number of points: \", len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, num_layers, **kwargs):\n",
    "\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        \n",
    "        self.L1 = tf.keras.layers.Dense(5, activation='tanh')\n",
    "        self.L2 = tf.keras.layers.Dense(10, activation='tanh')\n",
    "        self.L3 = tf.keras.layers.Dense(2, activation='tanh')\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        \n",
    "        h = self.L1(inputs)\n",
    "        h = self.L2(h)\n",
    "        h = self.L3(h)\n",
    "        \n",
    "        #h = self.conv_1(inputs)\n",
    "        #h = self.bn_1(h)\n",
    "        #h = self.conv_2(h)\n",
    "        #h = self.bn_2(h)\n",
    "        \n",
    "        return h #+ inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([199999, 2])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block1 = MLP(10, name='MLP1')\n",
    "block2 = MLP(10, name='MLP2')\n",
    "\n",
    "block1(tf.random.normal(x_train.shape)).shape\n",
    "block2(tf.random.normal(x_train.shape)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def get_shift_and_log_scale_resnet(input_shape, blocks):\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    h = inputs\n",
    "\n",
    "    for block in blocks:\n",
    "        h = block(h)\n",
    "\n",
    "    shift, log_scale = h, h #tf.split(h, num_or_size_splits=2, axis=-1)\n",
    "    log_scale = tf.math.tanh(log_scale)\n",
    "    return Model(inputs=inputs, outputs=[shift, log_scale], name='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_and_log_scale = get_shift_and_log_scale_resnet((2), [block1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"name\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "MLP1 (MLP)                   (None, 2)                 97        \n",
      "_________________________________________________________________\n",
      "tf.math.tanh_3 (TFOpLambda)  (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shift_and_log_scale.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineCouplingLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, shift_and_log_scale_fn, mask):\n",
    "        \n",
    "        super(AffineCouplingLayer, self).__init__()\n",
    "        self.shift_and_log_scale_fn = shift_and_log_scale_fn\n",
    "        self.b = tf.cast(mask, tf.float32)\n",
    "\n",
    "    def call(self, x, inverse):\n",
    "        \n",
    "        if inverse == 1:\n",
    "            t, log_s = self.shift_and_log_scale_fn(x * self.b)\n",
    "            y = self.b * x + (1 - self.b) * (x * tf.exp(log_s) + t)\n",
    "            return y\n",
    "        \n",
    "        if inverse == 0:\n",
    "            t, log_s = self.shift_and_log_scale_fn(x * self.b)\n",
    "            y = self.b * x + (1 - self.b) * ((x - t) * tf.exp(-log_s))\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(R, self).__init__()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return inputs*tf.constant([[1., -1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealNVPModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, shift_and_log_scale, **kwargs):\n",
    "        \n",
    "        super(RealNVPModel, self).__init__()\n",
    "        self.R = R()\n",
    "        mask = tf.constant([[0., 1.]])\n",
    "        mask1 = tf.constant([[1., 0.]])\n",
    "        self.acl1 = AffineCouplingLayer(shift_and_log_scale, mask)\n",
    "        self.acl2 = AffineCouplingLayer(shift_and_log_scale, mask1)\n",
    "        self.acl3 = AffineCouplingLayer(shift_and_log_scale, mask)\n",
    "        self.acl4 = AffineCouplingLayer(shift_and_log_scale, mask1)\n",
    "        self.acl5 = AffineCouplingLayer(shift_and_log_scale, mask)\n",
    "        self.acl6 = AffineCouplingLayer(shift_and_log_scale, mask)\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        \n",
    "        a = self.R(input_tensor)\n",
    "\n",
    "        a = self.acl1(a, 1)\n",
    "        a = self.acl2(a, 1)\n",
    "        a = self.acl3(a, 1)\n",
    "        a = self.acl4(a, 1)\n",
    "        a = self.acl5(a, 1)\n",
    "        a = self.acl6(a, 1)\n",
    "        \n",
    "        a = self.R(a)\n",
    "\n",
    "        a = self.acl6(a, 0)\n",
    "        a = self.acl5(a, 0)\n",
    "        a = self.acl4(a, 0)\n",
    "        a = self.acl3(a, 0)\n",
    "        a = self.acl2(a, 0)\n",
    "        a = self.acl1(a, 0)\n",
    "        \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = MLP(10, name='MLP1')\n",
    "\n",
    "shift_and_log_scale = get_shift_and_log_scale_resnet((2), [block1])\n",
    "\n",
    "model = RealNVPModel(shift_and_log_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECAYING LEARNING RATE\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        #print(lr)\n",
    "        return lr\n",
    "    else:\n",
    "        #print(lr)\n",
    "        return lr*tf.math.exp(-0.001)\n",
    "    \n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss= tf.keras.losses.MeanSquaredError(),\n",
    "    #loss = custom_loss,\n",
    "    #optimizer=tfps.optimizers.bfgs_minimize(), #clipvalue = 0.001),\n",
    "    #optimizer=keras.optimizers.SGD(0.00001), #, clipvalue = 0.001),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.01), #, clipvalue = 0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 [==============================] - 1s 232ms/step - loss: 0.9009 - accuracy: 0.5285 - val_loss: 0.4814 - val_accuracy: 0.5440\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4942 - accuracy: 0.5403 - val_loss: 0.4952 - val_accuracy: 0.5447\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4823 - accuracy: 0.5436 - val_loss: 0.3949 - val_accuracy: 0.5676\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3827 - accuracy: 0.5546 - val_loss: 0.3411 - val_accuracy: 0.5386\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3435 - accuracy: 0.5364 - val_loss: 0.3584 - val_accuracy: 0.5279\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3674 - accuracy: 0.5276 - val_loss: 0.3912 - val_accuracy: 0.5235\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3951 - accuracy: 0.5240 - val_loss: 0.3961 - val_accuracy: 0.5237\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3930 - accuracy: 0.5245 - val_loss: 0.3732 - val_accuracy: 0.5266\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3674 - accuracy: 0.5290 - val_loss: 0.3464 - val_accuracy: 0.5343\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3454 - accuracy: 0.5376 - val_loss: 0.3441 - val_accuracy: 0.5458\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3493 - accuracy: 0.5484 - val_loss: 0.3577 - val_accuracy: 0.5534\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3616 - accuracy: 0.5543 - val_loss: 0.3566 - val_accuracy: 0.5529\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3564 - accuracy: 0.5514 - val_loss: 0.3432 - val_accuracy: 0.5447\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3433 - accuracy: 0.5436 - val_loss: 0.3376 - val_accuracy: 0.5365\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3397 - accuracy: 0.5362 - val_loss: 0.3413 - val_accuracy: 0.5315\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3436 - accuracy: 0.5314 - val_loss: 0.3442 - val_accuracy: 0.5300\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3453 - accuracy: 0.5298 - val_loss: 0.3420 - val_accuracy: 0.5302\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3424 - accuracy: 0.5307 - val_loss: 0.3376 - val_accuracy: 0.5319\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3384 - accuracy: 0.5330 - val_loss: 0.3354 - val_accuracy: 0.5347\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3374 - accuracy: 0.5357 - val_loss: 0.3365 - val_accuracy: 0.5378\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3388 - accuracy: 0.5378 - val_loss: 0.3377 - val_accuracy: 0.5386\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3398 - accuracy: 0.5384 - val_loss: 0.3371 - val_accuracy: 0.5376\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3389 - accuracy: 0.5374 - val_loss: 0.3360 - val_accuracy: 0.5357\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3377 - accuracy: 0.5352 - val_loss: 0.3358 - val_accuracy: 0.5337\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3376 - accuracy: 0.5339 - val_loss: 0.3364 - val_accuracy: 0.5325\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3381 - accuracy: 0.5327 - val_loss: 0.3367 - val_accuracy: 0.5324\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3382 - accuracy: 0.5326 - val_loss: 0.3362 - val_accuracy: 0.5327\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3376 - accuracy: 0.5333 - val_loss: 0.3355 - val_accuracy: 0.5339\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3371 - accuracy: 0.5347 - val_loss: 0.3352 - val_accuracy: 0.5352\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3370 - accuracy: 0.5357 - val_loss: 0.3353 - val_accuracy: 0.5360\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3372 - accuracy: 0.5364 - val_loss: 0.3353 - val_accuracy: 0.5362\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3371 - accuracy: 0.5364 - val_loss: 0.3350 - val_accuracy: 0.5362\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3368 - accuracy: 0.5361 - val_loss: 0.3350 - val_accuracy: 0.5355\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3367 - accuracy: 0.5355 - val_loss: 0.3351 - val_accuracy: 0.5343\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3367 - accuracy: 0.5349 - val_loss: 0.3351 - val_accuracy: 0.5338\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3367 - accuracy: 0.5349 - val_loss: 0.3350 - val_accuracy: 0.5343\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3366 - accuracy: 0.5353 - val_loss: 0.3348 - val_accuracy: 0.5357\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3365 - accuracy: 0.5361 - val_loss: 0.3348 - val_accuracy: 0.5362\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3365 - accuracy: 0.5368 - val_loss: 0.3348 - val_accuracy: 0.5362\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3365 - accuracy: 0.5371 - val_loss: 0.3347 - val_accuracy: 0.5362\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3364 - accuracy: 0.5368 - val_loss: 0.3346 - val_accuracy: 0.5362\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3363 - accuracy: 0.5365 - val_loss: 0.3346 - val_accuracy: 0.5357\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3363 - accuracy: 0.5358 - val_loss: 0.3346 - val_accuracy: 0.5353\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3362 - accuracy: 0.5356 - val_loss: 0.3345 - val_accuracy: 0.5357\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3362 - accuracy: 0.5358 - val_loss: 0.3344 - val_accuracy: 0.5358\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3361 - accuracy: 0.5362 - val_loss: 0.3344 - val_accuracy: 0.5357\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3361 - accuracy: 0.5364 - val_loss: 0.3343 - val_accuracy: 0.5358\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3360 - accuracy: 0.5364 - val_loss: 0.3343 - val_accuracy: 0.5358\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.3360 - accuracy: 0.5363 - val_loss: 0.3342 - val_accuracy: 0.5357\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3359 - accuracy: 0.5361 - val_loss: 0.3342 - val_accuracy: 0.5354\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3359 - accuracy: 0.5361 - val_loss: 0.3341 - val_accuracy: 0.5354\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3358 - accuracy: 0.5360 - val_loss: 0.3341 - val_accuracy: 0.5355\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3358 - accuracy: 0.5360 - val_loss: 0.3340 - val_accuracy: 0.5357\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3357 - accuracy: 0.5363 - val_loss: 0.3339 - val_accuracy: 0.5360\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3356 - accuracy: 0.5364 - val_loss: 0.3339 - val_accuracy: 0.5359\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3356 - accuracy: 0.5365 - val_loss: 0.3338 - val_accuracy: 0.5360\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3355 - accuracy: 0.5365 - val_loss: 0.3338 - val_accuracy: 0.5360\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3355 - accuracy: 0.5364 - val_loss: 0.3337 - val_accuracy: 0.5358\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3354 - accuracy: 0.5364 - val_loss: 0.3337 - val_accuracy: 0.5358\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3354 - accuracy: 0.5364 - val_loss: 0.3336 - val_accuracy: 0.5361\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3353 - accuracy: 0.5365 - val_loss: 0.3336 - val_accuracy: 0.5359\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3352 - accuracy: 0.5366 - val_loss: 0.3335 - val_accuracy: 0.5360\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3352 - accuracy: 0.5366 - val_loss: 0.3334 - val_accuracy: 0.5360\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3351 - accuracy: 0.5366 - val_loss: 0.3334 - val_accuracy: 0.5358\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3351 - accuracy: 0.5365 - val_loss: 0.3333 - val_accuracy: 0.5360\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3350 - accuracy: 0.5364 - val_loss: 0.3333 - val_accuracy: 0.5361\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3349 - accuracy: 0.5365 - val_loss: 0.3332 - val_accuracy: 0.5361\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3349 - accuracy: 0.5365 - val_loss: 0.3331 - val_accuracy: 0.5362\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3348 - accuracy: 0.5365 - val_loss: 0.3331 - val_accuracy: 0.5362\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3347 - accuracy: 0.5365 - val_loss: 0.3330 - val_accuracy: 0.5362\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3347 - accuracy: 0.5365 - val_loss: 0.3329 - val_accuracy: 0.5363\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3346 - accuracy: 0.5365 - val_loss: 0.3329 - val_accuracy: 0.5362\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3345 - accuracy: 0.5366 - val_loss: 0.3328 - val_accuracy: 0.5363\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3345 - accuracy: 0.5366 - val_loss: 0.3327 - val_accuracy: 0.5361\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3344 - accuracy: 0.5366 - val_loss: 0.3327 - val_accuracy: 0.5363\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3343 - accuracy: 0.5365 - val_loss: 0.3326 - val_accuracy: 0.5365\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3343 - accuracy: 0.5365 - val_loss: 0.3325 - val_accuracy: 0.5366\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3342 - accuracy: 0.5365 - val_loss: 0.3325 - val_accuracy: 0.5366\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3341 - accuracy: 0.5365 - val_loss: 0.3324 - val_accuracy: 0.5365\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3341 - accuracy: 0.5366 - val_loss: 0.3323 - val_accuracy: 0.5367\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3340 - accuracy: 0.5366 - val_loss: 0.3323 - val_accuracy: 0.5367\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3339 - accuracy: 0.5366 - val_loss: 0.3322 - val_accuracy: 0.5365\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3339 - accuracy: 0.5366 - val_loss: 0.3321 - val_accuracy: 0.5365\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3338 - accuracy: 0.5366 - val_loss: 0.3321 - val_accuracy: 0.5365\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3337 - accuracy: 0.5366 - val_loss: 0.3320 - val_accuracy: 0.5365\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3336 - accuracy: 0.5366 - val_loss: 0.3319 - val_accuracy: 0.5364\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3336 - accuracy: 0.5366 - val_loss: 0.3318 - val_accuracy: 0.5363\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3335 - accuracy: 0.5366 - val_loss: 0.3318 - val_accuracy: 0.5365\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3334 - accuracy: 0.5366 - val_loss: 0.3317 - val_accuracy: 0.5366\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3334 - accuracy: 0.5367 - val_loss: 0.3316 - val_accuracy: 0.5365\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3333 - accuracy: 0.5367 - val_loss: 0.3316 - val_accuracy: 0.5366\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3332 - accuracy: 0.5367 - val_loss: 0.3315 - val_accuracy: 0.5368\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3332 - accuracy: 0.5367 - val_loss: 0.3314 - val_accuracy: 0.5368\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3331 - accuracy: 0.5368 - val_loss: 0.3313 - val_accuracy: 0.5365\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3330 - accuracy: 0.5368 - val_loss: 0.3313 - val_accuracy: 0.5365\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3329 - accuracy: 0.5369 - val_loss: 0.3312 - val_accuracy: 0.5365\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3329 - accuracy: 0.5369 - val_loss: 0.3311 - val_accuracy: 0.5364\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3328 - accuracy: 0.5370 - val_loss: 0.3311 - val_accuracy: 0.5364\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3327 - accuracy: 0.5370 - val_loss: 0.3310 - val_accuracy: 0.5364\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3327 - accuracy: 0.5370 - val_loss: 0.3309 - val_accuracy: 0.5364\n",
      "Epoch 101/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3326 - accuracy: 0.5370 - val_loss: 0.3308 - val_accuracy: 0.5365\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3325 - accuracy: 0.5371 - val_loss: 0.3308 - val_accuracy: 0.5367\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3324 - accuracy: 0.5372 - val_loss: 0.3307 - val_accuracy: 0.5365\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3324 - accuracy: 0.5372 - val_loss: 0.3306 - val_accuracy: 0.5366\n",
      "Epoch 105/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3323 - accuracy: 0.5372 - val_loss: 0.3306 - val_accuracy: 0.5367\n",
      "Epoch 106/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3322 - accuracy: 0.5371 - val_loss: 0.3305 - val_accuracy: 0.5367\n",
      "Epoch 107/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3322 - accuracy: 0.5371 - val_loss: 0.3304 - val_accuracy: 0.5367\n",
      "Epoch 108/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3321 - accuracy: 0.5371 - val_loss: 0.3303 - val_accuracy: 0.5369\n",
      "Epoch 109/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3320 - accuracy: 0.5371 - val_loss: 0.3303 - val_accuracy: 0.5368\n",
      "Epoch 110/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3319 - accuracy: 0.5371 - val_loss: 0.3302 - val_accuracy: 0.5369\n",
      "Epoch 111/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3319 - accuracy: 0.5372 - val_loss: 0.3301 - val_accuracy: 0.5371\n",
      "Epoch 112/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3318 - accuracy: 0.5371 - val_loss: 0.3301 - val_accuracy: 0.5368\n",
      "Epoch 113/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.3317 - accuracy: 0.5372 - val_loss: 0.3300 - val_accuracy: 0.5367\n",
      "Epoch 114/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3317 - accuracy: 0.5371 - val_loss: 0.3299 - val_accuracy: 0.5368\n",
      "Epoch 115/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3316 - accuracy: 0.5371 - val_loss: 0.3298 - val_accuracy: 0.5367\n",
      "Epoch 116/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3315 - accuracy: 0.5372 - val_loss: 0.3298 - val_accuracy: 0.5369\n",
      "Epoch 117/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3314 - accuracy: 0.5372 - val_loss: 0.3297 - val_accuracy: 0.5371\n",
      "Epoch 118/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3314 - accuracy: 0.5371 - val_loss: 0.3296 - val_accuracy: 0.5371\n",
      "Epoch 119/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.3313 - accuracy: 0.5371 - val_loss: 0.3296 - val_accuracy: 0.5371\n",
      "Epoch 120/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3312 - accuracy: 0.5372 - val_loss: 0.3295 - val_accuracy: 0.5371\n",
      "Epoch 121/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3312 - accuracy: 0.5372 - val_loss: 0.3294 - val_accuracy: 0.5372\n",
      "Epoch 122/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3311 - accuracy: 0.5373 - val_loss: 0.3293 - val_accuracy: 0.5370\n",
      "Epoch 123/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3310 - accuracy: 0.5372 - val_loss: 0.3293 - val_accuracy: 0.5370\n",
      "Epoch 124/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3309 - accuracy: 0.5373 - val_loss: 0.3292 - val_accuracy: 0.5371\n",
      "Epoch 125/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3309 - accuracy: 0.5372 - val_loss: 0.3291 - val_accuracy: 0.5372\n",
      "Epoch 126/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3308 - accuracy: 0.5371 - val_loss: 0.3291 - val_accuracy: 0.5372\n",
      "Epoch 127/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3307 - accuracy: 0.5371 - val_loss: 0.3290 - val_accuracy: 0.5372\n",
      "Epoch 128/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3307 - accuracy: 0.5370 - val_loss: 0.3289 - val_accuracy: 0.5371\n",
      "Epoch 129/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3306 - accuracy: 0.5371 - val_loss: 0.3288 - val_accuracy: 0.5370\n",
      "Epoch 130/1000\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.3305 - accuracy: 0.5371 - val_loss: 0.3288 - val_accuracy: 0.5369\n",
      "Epoch 131/1000\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.3304 - accuracy: 0.5371 - val_loss: 0.3287 - val_accuracy: 0.5368\n",
      "Epoch 132/1000\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.3304 - accuracy: 0.5370 - val_loss: 0.3286 - val_accuracy: 0.5368\n",
      "Epoch 133/1000\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.3303 - accuracy: 0.5370 - val_loss: 0.3285 - val_accuracy: 0.5368\n",
      "Epoch 134/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3302 - accuracy: 0.5369 - val_loss: 0.3285 - val_accuracy: 0.5366\n",
      "Epoch 135/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3302 - accuracy: 0.5370 - val_loss: 0.3284 - val_accuracy: 0.5368\n",
      "Epoch 136/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3301 - accuracy: 0.5370 - val_loss: 0.3283 - val_accuracy: 0.5366\n",
      "Epoch 137/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3300 - accuracy: 0.5370 - val_loss: 0.3283 - val_accuracy: 0.5367\n",
      "Epoch 138/1000\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.3299 - accuracy: 0.5370 - val_loss: 0.3282 - val_accuracy: 0.5368\n",
      "Epoch 139/1000\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.3299 - accuracy: 0.5370 - val_loss: 0.3281 - val_accuracy: 0.5367\n",
      "Epoch 140/1000\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.3298 - accuracy: 0.5370 - val_loss: 0.3280 - val_accuracy: 0.5366\n",
      "Epoch 141/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3297 - accuracy: 0.5369 - val_loss: 0.3280 - val_accuracy: 0.5365\n",
      "Epoch 142/1000\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.3296 - accuracy: 0.5369 - val_loss: 0.3279 - val_accuracy: 0.5367\n",
      "Epoch 143/1000\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.3296 - accuracy: 0.5369 - val_loss: 0.3278 - val_accuracy: 0.5366\n",
      "Epoch 144/1000\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.3295 - accuracy: 0.5368 - val_loss: 0.3277 - val_accuracy: 0.5368\n",
      "Epoch 145/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3294 - accuracy: 0.5368 - val_loss: 0.3277 - val_accuracy: 0.5368\n",
      "Epoch 146/1000\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.3293 - accuracy: 0.5367 - val_loss: 0.3276 - val_accuracy: 0.5368\n",
      "Epoch 147/1000\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.3293 - accuracy: 0.5367 - val_loss: 0.3275 - val_accuracy: 0.5368\n",
      "Epoch 148/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3292 - accuracy: 0.5367 - val_loss: 0.3274 - val_accuracy: 0.5368\n",
      "Epoch 149/1000\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.3291 - accuracy: 0.5367 - val_loss: 0.3274 - val_accuracy: 0.5368\n",
      "Epoch 150/1000\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.3291 - accuracy: 0.5366 - val_loss: 0.3273 - val_accuracy: 0.5368\n",
      "Epoch 151/1000\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.3290 - accuracy: 0.5366 - val_loss: 0.3272 - val_accuracy: 0.5368\n",
      "Epoch 152/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3289 - accuracy: 0.5366 - val_loss: 0.3271 - val_accuracy: 0.5367\n",
      "Epoch 153/1000\n",
      "2/2 [==============================] - 1s 330ms/step - loss: 0.3288 - accuracy: 0.5366 - val_loss: 0.3271 - val_accuracy: 0.5366\n",
      "Epoch 154/1000\n",
      "2/2 [==============================] - 1s 403ms/step - loss: 0.3288 - accuracy: 0.5365 - val_loss: 0.3270 - val_accuracy: 0.5367\n",
      "Epoch 155/1000\n",
      "2/2 [==============================] - 1s 404ms/step - loss: 0.3287 - accuracy: 0.5365 - val_loss: 0.3269 - val_accuracy: 0.5368\n",
      "Epoch 156/1000\n",
      "2/2 [==============================] - 1s 405ms/step - loss: 0.3286 - accuracy: 0.5364 - val_loss: 0.3269 - val_accuracy: 0.5365\n",
      "Epoch 157/1000\n",
      "2/2 [==============================] - 1s 405ms/step - loss: 0.3286 - accuracy: 0.5364 - val_loss: 0.3268 - val_accuracy: 0.5365\n",
      "Epoch 158/1000\n",
      "2/2 [==============================] - 1s 406ms/step - loss: 0.3285 - accuracy: 0.5363 - val_loss: 0.3267 - val_accuracy: 0.5367\n",
      "Epoch 159/1000\n",
      "2/2 [==============================] - 1s 406ms/step - loss: 0.3284 - accuracy: 0.5364 - val_loss: 0.3266 - val_accuracy: 0.5366\n",
      "Epoch 160/1000\n",
      "2/2 [==============================] - 1s 404ms/step - loss: 0.3284 - accuracy: 0.5363 - val_loss: 0.3266 - val_accuracy: 0.5365\n",
      "Epoch 161/1000\n",
      "2/2 [==============================] - 1s 404ms/step - loss: 0.3283 - accuracy: 0.5363 - val_loss: 0.3265 - val_accuracy: 0.5366\n",
      "Epoch 162/1000\n",
      "2/2 [==============================] - 1s 404ms/step - loss: 0.3282 - accuracy: 0.5362 - val_loss: 0.3264 - val_accuracy: 0.5362\n",
      "Epoch 163/1000\n",
      "2/2 [==============================] - 1s 405ms/step - loss: 0.3281 - accuracy: 0.5362 - val_loss: 0.3264 - val_accuracy: 0.5364\n",
      "Epoch 164/1000\n",
      "2/2 [==============================] - 1s 405ms/step - loss: 0.3281 - accuracy: 0.5361 - val_loss: 0.3263 - val_accuracy: 0.5361\n",
      "Epoch 165/1000\n",
      "2/2 [==============================] - 1s 405ms/step - loss: 0.3280 - accuracy: 0.5361 - val_loss: 0.3262 - val_accuracy: 0.5361\n",
      "Epoch 166/1000\n",
      "2/2 [==============================] - 1s 405ms/step - loss: 0.3279 - accuracy: 0.5360 - val_loss: 0.3262 - val_accuracy: 0.5362\n",
      "Epoch 167/1000\n",
      "2/2 [==============================] - 1s 406ms/step - loss: 0.3279 - accuracy: 0.5360 - val_loss: 0.3261 - val_accuracy: 0.5362\n",
      "Epoch 168/1000\n",
      "2/2 [==============================] - 1s 405ms/step - loss: 0.3278 - accuracy: 0.5360 - val_loss: 0.3260 - val_accuracy: 0.5362\n",
      "Epoch 169/1000\n",
      "2/2 [==============================] - 1s 219ms/step - loss: 0.3278 - accuracy: 0.5359 - val_loss: 0.3260 - val_accuracy: 0.5361\n",
      "Epoch 170/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3277 - accuracy: 0.5359 - val_loss: 0.3259 - val_accuracy: 0.5362\n",
      "Epoch 171/1000\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.3276 - accuracy: 0.5359 - val_loss: 0.3258 - val_accuracy: 0.5361\n",
      "Epoch 172/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3276 - accuracy: 0.5359 - val_loss: 0.3258 - val_accuracy: 0.5360\n",
      "Epoch 173/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3275 - accuracy: 0.5359 - val_loss: 0.3257 - val_accuracy: 0.5363\n",
      "Epoch 174/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3274 - accuracy: 0.5359 - val_loss: 0.3257 - val_accuracy: 0.5361\n",
      "Epoch 175/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3274 - accuracy: 0.5360 - val_loss: 0.3256 - val_accuracy: 0.5361\n",
      "Epoch 176/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3273 - accuracy: 0.5360 - val_loss: 0.3255 - val_accuracy: 0.5360\n",
      "Epoch 177/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3273 - accuracy: 0.5358 - val_loss: 0.3255 - val_accuracy: 0.5358\n",
      "Epoch 178/1000\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.3272 - accuracy: 0.5358 - val_loss: 0.3254 - val_accuracy: 0.5361\n",
      "Epoch 179/1000\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.3271 - accuracy: 0.5359 - val_loss: 0.3254 - val_accuracy: 0.5361\n",
      "Epoch 180/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3271 - accuracy: 0.5359 - val_loss: 0.3253 - val_accuracy: 0.5359\n",
      "Epoch 181/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.3270 - accuracy: 0.5358 - val_loss: 0.3253 - val_accuracy: 0.5357\n",
      "Epoch 182/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3270 - accuracy: 0.5357 - val_loss: 0.3252 - val_accuracy: 0.5359\n",
      "Epoch 183/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3269 - accuracy: 0.5358 - val_loss: 0.3252 - val_accuracy: 0.5358\n",
      "Epoch 184/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3269 - accuracy: 0.5358 - val_loss: 0.3251 - val_accuracy: 0.5357\n",
      "Epoch 185/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3268 - accuracy: 0.5357 - val_loss: 0.3250 - val_accuracy: 0.5358\n",
      "Epoch 186/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3268 - accuracy: 0.5357 - val_loss: 0.3250 - val_accuracy: 0.5355\n",
      "Epoch 187/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3267 - accuracy: 0.5357 - val_loss: 0.3249 - val_accuracy: 0.5355\n",
      "Epoch 188/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3267 - accuracy: 0.5358 - val_loss: 0.3249 - val_accuracy: 0.5355\n",
      "Epoch 189/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3266 - accuracy: 0.5357 - val_loss: 0.3248 - val_accuracy: 0.5356\n",
      "Epoch 190/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3265 - accuracy: 0.5358 - val_loss: 0.3248 - val_accuracy: 0.5357\n",
      "Epoch 191/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3265 - accuracy: 0.5358 - val_loss: 0.3247 - val_accuracy: 0.5355\n",
      "Epoch 192/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3264 - accuracy: 0.5358 - val_loss: 0.3247 - val_accuracy: 0.5357\n",
      "Epoch 193/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3264 - accuracy: 0.5358 - val_loss: 0.3246 - val_accuracy: 0.5357\n",
      "Epoch 194/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3263 - accuracy: 0.5358 - val_loss: 0.3246 - val_accuracy: 0.5357\n",
      "Epoch 195/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3263 - accuracy: 0.5358 - val_loss: 0.3246 - val_accuracy: 0.5357\n",
      "Epoch 196/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3262 - accuracy: 0.5358 - val_loss: 0.3245 - val_accuracy: 0.5356\n",
      "Epoch 197/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3262 - accuracy: 0.5358 - val_loss: 0.3245 - val_accuracy: 0.5357\n",
      "Epoch 198/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3261 - accuracy: 0.5358 - val_loss: 0.3244 - val_accuracy: 0.5357\n",
      "Epoch 199/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3261 - accuracy: 0.5358 - val_loss: 0.3244 - val_accuracy: 0.5358\n",
      "Epoch 200/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3261 - accuracy: 0.5359 - val_loss: 0.3243 - val_accuracy: 0.5358\n",
      "Epoch 201/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.3260 - accuracy: 0.5360 - val_loss: 0.3243 - val_accuracy: 0.5357\n",
      "Epoch 202/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3260 - accuracy: 0.5359 - val_loss: 0.3242 - val_accuracy: 0.5357\n",
      "Epoch 203/1000\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 0.3259 - accuracy: 0.5359 - val_loss: 0.3242 - val_accuracy: 0.5357\n",
      "Epoch 204/1000\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 0.3259 - accuracy: 0.5360 - val_loss: 0.3241 - val_accuracy: 0.5357\n",
      "Epoch 205/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3258 - accuracy: 0.5360 - val_loss: 0.3241 - val_accuracy: 0.5357\n",
      "Epoch 206/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3258 - accuracy: 0.5360 - val_loss: 0.3241 - val_accuracy: 0.5356\n",
      "Epoch 207/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3257 - accuracy: 0.5361 - val_loss: 0.3240 - val_accuracy: 0.5358\n",
      "Epoch 208/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3257 - accuracy: 0.5361 - val_loss: 0.3240 - val_accuracy: 0.5357\n",
      "Epoch 209/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3256 - accuracy: 0.5361 - val_loss: 0.3239 - val_accuracy: 0.5356\n",
      "Epoch 210/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3256 - accuracy: 0.5362 - val_loss: 0.3239 - val_accuracy: 0.5354\n",
      "Epoch 211/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3255 - accuracy: 0.5363 - val_loss: 0.3238 - val_accuracy: 0.5355\n",
      "Epoch 212/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3255 - accuracy: 0.5363 - val_loss: 0.3238 - val_accuracy: 0.5355\n",
      "Epoch 213/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3254 - accuracy: 0.5363 - val_loss: 0.3238 - val_accuracy: 0.5354\n",
      "Epoch 214/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3254 - accuracy: 0.5363 - val_loss: 0.3237 - val_accuracy: 0.5355\n",
      "Epoch 215/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3253 - accuracy: 0.5364 - val_loss: 0.3237 - val_accuracy: 0.5357\n",
      "Epoch 216/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3253 - accuracy: 0.5364 - val_loss: 0.3236 - val_accuracy: 0.5354\n",
      "Epoch 217/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3252 - accuracy: 0.5364 - val_loss: 0.3236 - val_accuracy: 0.5357\n",
      "Epoch 218/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3252 - accuracy: 0.5365 - val_loss: 0.3235 - val_accuracy: 0.5354\n",
      "Epoch 219/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3252 - accuracy: 0.5365 - val_loss: 0.3235 - val_accuracy: 0.5354\n",
      "Epoch 220/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3251 - accuracy: 0.5365 - val_loss: 0.3234 - val_accuracy: 0.5354\n",
      "Epoch 221/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3251 - accuracy: 0.5365 - val_loss: 0.3234 - val_accuracy: 0.5353\n",
      "Epoch 222/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3250 - accuracy: 0.5366 - val_loss: 0.3234 - val_accuracy: 0.5354\n",
      "Epoch 223/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3250 - accuracy: 0.5366 - val_loss: 0.3233 - val_accuracy: 0.5354\n",
      "Epoch 224/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3249 - accuracy: 0.5367 - val_loss: 0.3233 - val_accuracy: 0.5357\n",
      "Epoch 225/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3249 - accuracy: 0.5368 - val_loss: 0.3232 - val_accuracy: 0.5357\n",
      "Epoch 226/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3248 - accuracy: 0.5368 - val_loss: 0.3232 - val_accuracy: 0.5357\n",
      "Epoch 227/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3248 - accuracy: 0.5368 - val_loss: 0.3231 - val_accuracy: 0.5357\n",
      "Epoch 228/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3247 - accuracy: 0.5369 - val_loss: 0.3231 - val_accuracy: 0.5357\n",
      "Epoch 229/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3247 - accuracy: 0.5369 - val_loss: 0.3230 - val_accuracy: 0.5358\n",
      "Epoch 230/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3246 - accuracy: 0.5370 - val_loss: 0.3230 - val_accuracy: 0.5358\n",
      "Epoch 231/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3246 - accuracy: 0.5370 - val_loss: 0.3230 - val_accuracy: 0.5360\n",
      "Epoch 232/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3245 - accuracy: 0.5370 - val_loss: 0.3229 - val_accuracy: 0.5360\n",
      "Epoch 233/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3245 - accuracy: 0.5370 - val_loss: 0.3229 - val_accuracy: 0.5362\n",
      "Epoch 234/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3244 - accuracy: 0.5372 - val_loss: 0.3228 - val_accuracy: 0.5363\n",
      "Epoch 235/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3244 - accuracy: 0.5372 - val_loss: 0.3228 - val_accuracy: 0.5362\n",
      "Epoch 236/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3243 - accuracy: 0.5372 - val_loss: 0.3227 - val_accuracy: 0.5362\n",
      "Epoch 237/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3243 - accuracy: 0.5372 - val_loss: 0.3227 - val_accuracy: 0.5363\n",
      "Epoch 238/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3242 - accuracy: 0.5372 - val_loss: 0.3226 - val_accuracy: 0.5365\n",
      "Epoch 239/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3242 - accuracy: 0.5372 - val_loss: 0.3226 - val_accuracy: 0.5365\n",
      "Epoch 240/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3241 - accuracy: 0.5373 - val_loss: 0.3225 - val_accuracy: 0.5365\n",
      "Epoch 241/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3241 - accuracy: 0.5374 - val_loss: 0.3225 - val_accuracy: 0.5368\n",
      "Epoch 242/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3240 - accuracy: 0.5374 - val_loss: 0.3224 - val_accuracy: 0.5369\n",
      "Epoch 243/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3240 - accuracy: 0.5374 - val_loss: 0.3224 - val_accuracy: 0.5369\n",
      "Epoch 244/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3239 - accuracy: 0.5375 - val_loss: 0.3224 - val_accuracy: 0.5369\n",
      "Epoch 245/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3239 - accuracy: 0.5375 - val_loss: 0.3223 - val_accuracy: 0.5369\n",
      "Epoch 246/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3238 - accuracy: 0.5375 - val_loss: 0.3223 - val_accuracy: 0.5371\n",
      "Epoch 247/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3238 - accuracy: 0.5375 - val_loss: 0.3222 - val_accuracy: 0.5371\n",
      "Epoch 248/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3237 - accuracy: 0.5376 - val_loss: 0.3222 - val_accuracy: 0.5372\n",
      "Epoch 249/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3237 - accuracy: 0.5377 - val_loss: 0.3221 - val_accuracy: 0.5372\n",
      "Epoch 250/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3236 - accuracy: 0.5378 - val_loss: 0.3221 - val_accuracy: 0.5375\n",
      "Epoch 251/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3235 - accuracy: 0.5379 - val_loss: 0.3220 - val_accuracy: 0.5375\n",
      "Epoch 252/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3235 - accuracy: 0.5379 - val_loss: 0.3220 - val_accuracy: 0.5375\n",
      "Epoch 253/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3234 - accuracy: 0.5380 - val_loss: 0.3219 - val_accuracy: 0.5375\n",
      "Epoch 254/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3234 - accuracy: 0.5380 - val_loss: 0.3219 - val_accuracy: 0.5377\n",
      "Epoch 255/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3233 - accuracy: 0.5381 - val_loss: 0.3218 - val_accuracy: 0.5378\n",
      "Epoch 256/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3233 - accuracy: 0.5381 - val_loss: 0.3218 - val_accuracy: 0.5375\n",
      "Epoch 257/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3232 - accuracy: 0.5381 - val_loss: 0.3217 - val_accuracy: 0.5375\n",
      "Epoch 258/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3232 - accuracy: 0.5382 - val_loss: 0.3217 - val_accuracy: 0.5379\n",
      "Epoch 259/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3231 - accuracy: 0.5382 - val_loss: 0.3216 - val_accuracy: 0.5379\n",
      "Epoch 260/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3231 - accuracy: 0.5383 - val_loss: 0.3216 - val_accuracy: 0.5380\n",
      "Epoch 261/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3230 - accuracy: 0.5383 - val_loss: 0.3215 - val_accuracy: 0.5382\n",
      "Epoch 262/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3229 - accuracy: 0.5384 - val_loss: 0.3215 - val_accuracy: 0.5382\n",
      "Epoch 263/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3229 - accuracy: 0.5384 - val_loss: 0.3214 - val_accuracy: 0.5383\n",
      "Epoch 264/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3228 - accuracy: 0.5385 - val_loss: 0.3213 - val_accuracy: 0.5383\n",
      "Epoch 265/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3228 - accuracy: 0.5385 - val_loss: 0.3213 - val_accuracy: 0.5386\n",
      "Epoch 266/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3227 - accuracy: 0.5386 - val_loss: 0.3212 - val_accuracy: 0.5386\n",
      "Epoch 267/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3227 - accuracy: 0.5387 - val_loss: 0.3212 - val_accuracy: 0.5386\n",
      "Epoch 268/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3226 - accuracy: 0.5386 - val_loss: 0.3212 - val_accuracy: 0.5386\n",
      "Epoch 269/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3225 - accuracy: 0.5388 - val_loss: 0.3211 - val_accuracy: 0.5386\n",
      "Epoch 270/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3225 - accuracy: 0.5388 - val_loss: 0.3210 - val_accuracy: 0.5386\n",
      "Epoch 271/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3224 - accuracy: 0.5388 - val_loss: 0.3210 - val_accuracy: 0.5386\n",
      "Epoch 272/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3224 - accuracy: 0.5388 - val_loss: 0.3209 - val_accuracy: 0.5386\n",
      "Epoch 273/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3223 - accuracy: 0.5389 - val_loss: 0.3209 - val_accuracy: 0.5387\n",
      "Epoch 274/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3223 - accuracy: 0.5390 - val_loss: 0.3208 - val_accuracy: 0.5387\n",
      "Epoch 275/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3222 - accuracy: 0.5391 - val_loss: 0.3208 - val_accuracy: 0.5387\n",
      "Epoch 276/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3221 - accuracy: 0.5391 - val_loss: 0.3207 - val_accuracy: 0.5389\n",
      "Epoch 277/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3221 - accuracy: 0.5392 - val_loss: 0.3207 - val_accuracy: 0.5390\n",
      "Epoch 278/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3220 - accuracy: 0.5392 - val_loss: 0.3206 - val_accuracy: 0.5391\n",
      "Epoch 279/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3220 - accuracy: 0.5394 - val_loss: 0.3206 - val_accuracy: 0.5391\n",
      "Epoch 280/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3219 - accuracy: 0.5394 - val_loss: 0.3205 - val_accuracy: 0.5393\n",
      "Epoch 281/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3219 - accuracy: 0.5394 - val_loss: 0.3205 - val_accuracy: 0.5394\n",
      "Epoch 282/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3218 - accuracy: 0.5395 - val_loss: 0.3204 - val_accuracy: 0.5396\n",
      "Epoch 283/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3217 - accuracy: 0.5396 - val_loss: 0.3204 - val_accuracy: 0.5396\n",
      "Epoch 284/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3217 - accuracy: 0.5396 - val_loss: 0.3203 - val_accuracy: 0.5396\n",
      "Epoch 285/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3216 - accuracy: 0.5397 - val_loss: 0.3202 - val_accuracy: 0.5395\n",
      "Epoch 286/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3216 - accuracy: 0.5398 - val_loss: 0.3202 - val_accuracy: 0.5396\n",
      "Epoch 287/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3215 - accuracy: 0.5399 - val_loss: 0.3201 - val_accuracy: 0.5393\n",
      "Epoch 288/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3215 - accuracy: 0.5398 - val_loss: 0.3201 - val_accuracy: 0.5395\n",
      "Epoch 289/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3214 - accuracy: 0.5401 - val_loss: 0.3200 - val_accuracy: 0.5394\n",
      "Epoch 290/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3213 - accuracy: 0.5401 - val_loss: 0.3200 - val_accuracy: 0.5396\n",
      "Epoch 291/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3213 - accuracy: 0.5401 - val_loss: 0.3199 - val_accuracy: 0.5396\n",
      "Epoch 292/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3212 - accuracy: 0.5403 - val_loss: 0.3199 - val_accuracy: 0.5396\n",
      "Epoch 293/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3212 - accuracy: 0.5403 - val_loss: 0.3198 - val_accuracy: 0.5397\n",
      "Epoch 294/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3211 - accuracy: 0.5403 - val_loss: 0.3198 - val_accuracy: 0.5398\n",
      "Epoch 295/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3211 - accuracy: 0.5405 - val_loss: 0.3197 - val_accuracy: 0.5400\n",
      "Epoch 296/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3210 - accuracy: 0.5404 - val_loss: 0.3197 - val_accuracy: 0.5399\n",
      "Epoch 297/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3210 - accuracy: 0.5406 - val_loss: 0.3196 - val_accuracy: 0.5401\n",
      "Epoch 298/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3209 - accuracy: 0.5406 - val_loss: 0.3196 - val_accuracy: 0.5397\n",
      "Epoch 299/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.3209 - accuracy: 0.5406 - val_loss: 0.3195 - val_accuracy: 0.5402\n",
      "Epoch 300/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.3208 - accuracy: 0.5407 - val_loss: 0.3195 - val_accuracy: 0.5400\n",
      "Epoch 301/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3208 - accuracy: 0.5407 - val_loss: 0.3194 - val_accuracy: 0.5403\n",
      "Epoch 302/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3207 - accuracy: 0.5409 - val_loss: 0.3194 - val_accuracy: 0.5404\n",
      "Epoch 303/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3206 - accuracy: 0.5408 - val_loss: 0.3193 - val_accuracy: 0.5403\n",
      "Epoch 304/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3206 - accuracy: 0.5409 - val_loss: 0.3193 - val_accuracy: 0.5406\n",
      "Epoch 305/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3205 - accuracy: 0.5410 - val_loss: 0.3192 - val_accuracy: 0.5406\n",
      "Epoch 306/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3205 - accuracy: 0.5410 - val_loss: 0.3192 - val_accuracy: 0.5407\n",
      "Epoch 307/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3204 - accuracy: 0.5411 - val_loss: 0.3191 - val_accuracy: 0.5408\n",
      "Epoch 308/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3204 - accuracy: 0.5411 - val_loss: 0.3191 - val_accuracy: 0.5405\n",
      "Epoch 309/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3203 - accuracy: 0.5412 - val_loss: 0.3191 - val_accuracy: 0.5406\n",
      "Epoch 310/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3203 - accuracy: 0.5412 - val_loss: 0.3190 - val_accuracy: 0.5407\n",
      "Epoch 311/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3203 - accuracy: 0.5413 - val_loss: 0.3190 - val_accuracy: 0.5408\n",
      "Epoch 312/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3202 - accuracy: 0.5413 - val_loss: 0.3189 - val_accuracy: 0.5410\n",
      "Epoch 313/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3202 - accuracy: 0.5414 - val_loss: 0.3189 - val_accuracy: 0.5408\n",
      "Epoch 314/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3201 - accuracy: 0.5415 - val_loss: 0.3188 - val_accuracy: 0.5411\n",
      "Epoch 315/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3201 - accuracy: 0.5415 - val_loss: 0.3188 - val_accuracy: 0.5411\n",
      "Epoch 316/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3200 - accuracy: 0.5414 - val_loss: 0.3187 - val_accuracy: 0.5411\n",
      "Epoch 317/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3200 - accuracy: 0.5415 - val_loss: 0.3187 - val_accuracy: 0.5416\n",
      "Epoch 318/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3199 - accuracy: 0.5416 - val_loss: 0.3187 - val_accuracy: 0.5411\n",
      "Epoch 319/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3199 - accuracy: 0.5416 - val_loss: 0.3186 - val_accuracy: 0.5417\n",
      "Epoch 320/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3198 - accuracy: 0.5418 - val_loss: 0.3186 - val_accuracy: 0.5415\n",
      "Epoch 321/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3198 - accuracy: 0.5418 - val_loss: 0.3185 - val_accuracy: 0.5418\n",
      "Epoch 322/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3198 - accuracy: 0.5419 - val_loss: 0.3185 - val_accuracy: 0.5419\n",
      "Epoch 323/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3197 - accuracy: 0.5418 - val_loss: 0.3185 - val_accuracy: 0.5418\n",
      "Epoch 324/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3197 - accuracy: 0.5418 - val_loss: 0.3184 - val_accuracy: 0.5423\n",
      "Epoch 325/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3197 - accuracy: 0.5419 - val_loss: 0.3184 - val_accuracy: 0.5419\n",
      "Epoch 326/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3196 - accuracy: 0.5419 - val_loss: 0.3184 - val_accuracy: 0.5421\n",
      "Epoch 327/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3196 - accuracy: 0.5420 - val_loss: 0.3183 - val_accuracy: 0.5422\n",
      "Epoch 328/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3195 - accuracy: 0.5419 - val_loss: 0.3183 - val_accuracy: 0.5423\n",
      "Epoch 329/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3195 - accuracy: 0.5420 - val_loss: 0.3183 - val_accuracy: 0.5425\n",
      "Epoch 330/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3195 - accuracy: 0.5421 - val_loss: 0.3182 - val_accuracy: 0.5426\n",
      "Epoch 331/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3194 - accuracy: 0.5420 - val_loss: 0.3182 - val_accuracy: 0.5424\n",
      "Epoch 332/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3194 - accuracy: 0.5422 - val_loss: 0.3181 - val_accuracy: 0.5424\n",
      "Epoch 333/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3194 - accuracy: 0.5422 - val_loss: 0.3181 - val_accuracy: 0.5429\n",
      "Epoch 334/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3193 - accuracy: 0.5422 - val_loss: 0.3181 - val_accuracy: 0.5426\n",
      "Epoch 335/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3193 - accuracy: 0.5424 - val_loss: 0.3181 - val_accuracy: 0.5433\n",
      "Epoch 336/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3193 - accuracy: 0.5422 - val_loss: 0.3180 - val_accuracy: 0.5430\n",
      "Epoch 337/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3192 - accuracy: 0.5424 - val_loss: 0.3180 - val_accuracy: 0.5430\n",
      "Epoch 338/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3192 - accuracy: 0.5424 - val_loss: 0.3180 - val_accuracy: 0.5432\n",
      "Epoch 339/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3192 - accuracy: 0.5425 - val_loss: 0.3179 - val_accuracy: 0.5430\n",
      "Epoch 340/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3192 - accuracy: 0.5425 - val_loss: 0.3179 - val_accuracy: 0.5433\n",
      "Epoch 341/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3191 - accuracy: 0.5425 - val_loss: 0.3179 - val_accuracy: 0.5433\n",
      "Epoch 342/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3191 - accuracy: 0.5426 - val_loss: 0.3179 - val_accuracy: 0.5433\n",
      "Epoch 343/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3191 - accuracy: 0.5424 - val_loss: 0.3178 - val_accuracy: 0.5433\n",
      "Epoch 344/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3190 - accuracy: 0.5425 - val_loss: 0.3178 - val_accuracy: 0.5434\n",
      "Epoch 345/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3190 - accuracy: 0.5424 - val_loss: 0.3178 - val_accuracy: 0.5436\n",
      "Epoch 346/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3190 - accuracy: 0.5425 - val_loss: 0.3178 - val_accuracy: 0.5436\n",
      "Epoch 347/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3190 - accuracy: 0.5426 - val_loss: 0.3177 - val_accuracy: 0.5436\n",
      "Epoch 348/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3189 - accuracy: 0.5425 - val_loss: 0.3177 - val_accuracy: 0.5435\n",
      "Epoch 349/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3189 - accuracy: 0.5428 - val_loss: 0.3177 - val_accuracy: 0.5436\n",
      "Epoch 350/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3189 - accuracy: 0.5427 - val_loss: 0.3177 - val_accuracy: 0.5436\n",
      "Epoch 351/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3189 - accuracy: 0.5427 - val_loss: 0.3176 - val_accuracy: 0.5437\n",
      "Epoch 352/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3188 - accuracy: 0.5428 - val_loss: 0.3176 - val_accuracy: 0.5436\n",
      "Epoch 353/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3188 - accuracy: 0.5426 - val_loss: 0.3176 - val_accuracy: 0.5437\n",
      "Epoch 354/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3188 - accuracy: 0.5428 - val_loss: 0.3176 - val_accuracy: 0.5438\n",
      "Epoch 355/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3188 - accuracy: 0.5426 - val_loss: 0.3175 - val_accuracy: 0.5439\n",
      "Epoch 356/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3187 - accuracy: 0.5427 - val_loss: 0.3175 - val_accuracy: 0.5439\n",
      "Epoch 357/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3187 - accuracy: 0.5429 - val_loss: 0.3175 - val_accuracy: 0.5440\n",
      "Epoch 358/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3187 - accuracy: 0.5427 - val_loss: 0.3175 - val_accuracy: 0.5440\n",
      "Epoch 359/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3187 - accuracy: 0.5428 - val_loss: 0.3175 - val_accuracy: 0.5440\n",
      "Epoch 360/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3187 - accuracy: 0.5430 - val_loss: 0.3175 - val_accuracy: 0.5442\n",
      "Epoch 361/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3187 - accuracy: 0.5429 - val_loss: 0.3174 - val_accuracy: 0.5442\n",
      "Epoch 362/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3186 - accuracy: 0.5430 - val_loss: 0.3174 - val_accuracy: 0.5440\n",
      "Epoch 363/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3186 - accuracy: 0.5428 - val_loss: 0.3174 - val_accuracy: 0.5438\n",
      "Epoch 364/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3186 - accuracy: 0.5428 - val_loss: 0.3174 - val_accuracy: 0.5442\n",
      "Epoch 365/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3186 - accuracy: 0.5429 - val_loss: 0.3174 - val_accuracy: 0.5436\n",
      "Epoch 366/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3186 - accuracy: 0.5428 - val_loss: 0.3173 - val_accuracy: 0.5442\n",
      "Epoch 367/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3186 - accuracy: 0.5430 - val_loss: 0.3173 - val_accuracy: 0.5443\n",
      "Epoch 368/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3185 - accuracy: 0.5428 - val_loss: 0.3173 - val_accuracy: 0.5441\n",
      "Epoch 369/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3185 - accuracy: 0.5429 - val_loss: 0.3173 - val_accuracy: 0.5443\n",
      "Epoch 370/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3185 - accuracy: 0.5429 - val_loss: 0.3173 - val_accuracy: 0.5439\n",
      "Epoch 371/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3185 - accuracy: 0.5429 - val_loss: 0.3173 - val_accuracy: 0.5443\n",
      "Epoch 372/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3185 - accuracy: 0.5432 - val_loss: 0.3173 - val_accuracy: 0.5440\n",
      "Epoch 373/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3185 - accuracy: 0.5429 - val_loss: 0.3173 - val_accuracy: 0.5443\n",
      "Epoch 374/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3185 - accuracy: 0.5431 - val_loss: 0.3172 - val_accuracy: 0.5441\n",
      "Epoch 375/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3184 - accuracy: 0.5430 - val_loss: 0.3172 - val_accuracy: 0.5442\n",
      "Epoch 376/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3184 - accuracy: 0.5430 - val_loss: 0.3172 - val_accuracy: 0.5441\n",
      "Epoch 377/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3184 - accuracy: 0.5430 - val_loss: 0.3172 - val_accuracy: 0.5440\n",
      "Epoch 378/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3184 - accuracy: 0.5430 - val_loss: 0.3172 - val_accuracy: 0.5443\n",
      "Epoch 379/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3184 - accuracy: 0.5432 - val_loss: 0.3172 - val_accuracy: 0.5443\n",
      "Epoch 380/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3184 - accuracy: 0.5431 - val_loss: 0.3172 - val_accuracy: 0.5441\n",
      "Epoch 381/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3184 - accuracy: 0.5432 - val_loss: 0.3172 - val_accuracy: 0.5444\n",
      "Epoch 382/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3184 - accuracy: 0.5432 - val_loss: 0.3171 - val_accuracy: 0.5442\n",
      "Epoch 383/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3184 - accuracy: 0.5432 - val_loss: 0.3171 - val_accuracy: 0.5444\n",
      "Epoch 384/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3184 - accuracy: 0.5431 - val_loss: 0.3171 - val_accuracy: 0.5442\n",
      "Epoch 385/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3183 - accuracy: 0.5432 - val_loss: 0.3171 - val_accuracy: 0.5443\n",
      "Epoch 386/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3183 - accuracy: 0.5432 - val_loss: 0.3171 - val_accuracy: 0.5443\n",
      "Epoch 387/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3183 - accuracy: 0.5432 - val_loss: 0.3171 - val_accuracy: 0.5444\n",
      "Epoch 388/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3183 - accuracy: 0.5431 - val_loss: 0.3171 - val_accuracy: 0.5443\n",
      "Epoch 389/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3183 - accuracy: 0.5432 - val_loss: 0.3171 - val_accuracy: 0.5446\n",
      "Epoch 390/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3183 - accuracy: 0.5432 - val_loss: 0.3171 - val_accuracy: 0.5444\n",
      "Epoch 391/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3183 - accuracy: 0.5432 - val_loss: 0.3171 - val_accuracy: 0.5444\n",
      "Epoch 392/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3183 - accuracy: 0.5433 - val_loss: 0.3171 - val_accuracy: 0.5443\n",
      "Epoch 393/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3183 - accuracy: 0.5431 - val_loss: 0.3170 - val_accuracy: 0.5444\n",
      "Epoch 394/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3183 - accuracy: 0.5434 - val_loss: 0.3170 - val_accuracy: 0.5445\n",
      "Epoch 395/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3182 - accuracy: 0.5432 - val_loss: 0.3170 - val_accuracy: 0.5444\n",
      "Epoch 396/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3182 - accuracy: 0.5433 - val_loss: 0.3170 - val_accuracy: 0.5445\n",
      "Epoch 397/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3182 - accuracy: 0.5433 - val_loss: 0.3170 - val_accuracy: 0.5444\n",
      "Epoch 398/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3182 - accuracy: 0.5432 - val_loss: 0.3170 - val_accuracy: 0.5445\n",
      "Epoch 399/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3182 - accuracy: 0.5434 - val_loss: 0.3170 - val_accuracy: 0.5444\n",
      "Epoch 400/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3182 - accuracy: 0.5433 - val_loss: 0.3170 - val_accuracy: 0.5445\n",
      "Epoch 401/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3182 - accuracy: 0.5434 - val_loss: 0.3170 - val_accuracy: 0.5441\n",
      "Epoch 402/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3182 - accuracy: 0.5431 - val_loss: 0.3170 - val_accuracy: 0.5446\n",
      "Epoch 403/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3182 - accuracy: 0.5436 - val_loss: 0.3170 - val_accuracy: 0.5443\n",
      "Epoch 404/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3182 - accuracy: 0.5433 - val_loss: 0.3170 - val_accuracy: 0.5445\n",
      "Epoch 405/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3182 - accuracy: 0.5435 - val_loss: 0.3170 - val_accuracy: 0.5446\n",
      "Epoch 406/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3182 - accuracy: 0.5434 - val_loss: 0.3170 - val_accuracy: 0.5441\n",
      "Epoch 407/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3182 - accuracy: 0.5434 - val_loss: 0.3169 - val_accuracy: 0.5447\n",
      "Epoch 408/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3182 - accuracy: 0.5435 - val_loss: 0.3169 - val_accuracy: 0.5444\n",
      "Epoch 409/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3182 - accuracy: 0.5435 - val_loss: 0.3169 - val_accuracy: 0.5446\n",
      "Epoch 410/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3181 - accuracy: 0.5435 - val_loss: 0.3169 - val_accuracy: 0.5444\n",
      "Epoch 411/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3181 - accuracy: 0.5434 - val_loss: 0.3169 - val_accuracy: 0.5447\n",
      "Epoch 412/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3181 - accuracy: 0.5435 - val_loss: 0.3169 - val_accuracy: 0.5444\n",
      "Epoch 413/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3181 - accuracy: 0.5434 - val_loss: 0.3169 - val_accuracy: 0.5447\n",
      "Epoch 414/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3181 - accuracy: 0.5436 - val_loss: 0.3169 - val_accuracy: 0.5444\n",
      "Epoch 415/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3181 - accuracy: 0.5434 - val_loss: 0.3169 - val_accuracy: 0.5447\n",
      "Epoch 416/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3181 - accuracy: 0.5436 - val_loss: 0.3169 - val_accuracy: 0.5447\n",
      "Epoch 417/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3181 - accuracy: 0.5435 - val_loss: 0.3169 - val_accuracy: 0.5444\n",
      "Epoch 418/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3181 - accuracy: 0.5434 - val_loss: 0.3169 - val_accuracy: 0.5448\n",
      "Epoch 419/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3181 - accuracy: 0.5436 - val_loss: 0.3169 - val_accuracy: 0.5445\n",
      "Epoch 420/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3181 - accuracy: 0.5434 - val_loss: 0.3169 - val_accuracy: 0.5447\n",
      "Epoch 421/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3181 - accuracy: 0.5436 - val_loss: 0.3169 - val_accuracy: 0.5447\n",
      "Epoch 422/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3181 - accuracy: 0.5434 - val_loss: 0.3169 - val_accuracy: 0.5445\n",
      "Epoch 423/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3181 - accuracy: 0.5435 - val_loss: 0.3169 - val_accuracy: 0.5446\n",
      "Epoch 424/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3181 - accuracy: 0.5435 - val_loss: 0.3169 - val_accuracy: 0.5446\n",
      "Epoch 425/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3181 - accuracy: 0.5435 - val_loss: 0.3169 - val_accuracy: 0.5447\n",
      "Epoch 426/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3181 - accuracy: 0.5435 - val_loss: 0.3169 - val_accuracy: 0.5444\n",
      "Epoch 427/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3181 - accuracy: 0.5435 - val_loss: 0.3168 - val_accuracy: 0.5446\n",
      "Epoch 428/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3181 - accuracy: 0.5436 - val_loss: 0.3168 - val_accuracy: 0.5445\n",
      "Epoch 429/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3181 - accuracy: 0.5434 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 430/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3180 - accuracy: 0.5436 - val_loss: 0.3168 - val_accuracy: 0.5446\n",
      "Epoch 431/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3180 - accuracy: 0.5435 - val_loss: 0.3168 - val_accuracy: 0.5445\n",
      "Epoch 432/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3180 - accuracy: 0.5436 - val_loss: 0.3168 - val_accuracy: 0.5444\n",
      "Epoch 433/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3180 - accuracy: 0.5435 - val_loss: 0.3168 - val_accuracy: 0.5444\n",
      "Epoch 434/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3180 - accuracy: 0.5436 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 435/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3180 - accuracy: 0.5435 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 436/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3180 - accuracy: 0.5438 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 437/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3180 - accuracy: 0.5435 - val_loss: 0.3168 - val_accuracy: 0.5445\n",
      "Epoch 438/1000\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.3180 - accuracy: 0.5434 - val_loss: 0.3168 - val_accuracy: 0.5449\n",
      "Epoch 439/1000\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.3180 - accuracy: 0.5436 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 440/1000\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.3180 - accuracy: 0.5436 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 441/1000\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 0.3180 - accuracy: 0.5435 - val_loss: 0.3168 - val_accuracy: 0.5446\n",
      "Epoch 442/1000\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.3180 - accuracy: 0.5435 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 443/1000\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 0.3180 - accuracy: 0.5436 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 444/1000\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.3180 - accuracy: 0.5435 - val_loss: 0.3168 - val_accuracy: 0.5448\n",
      "Epoch 445/1000\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.3180 - accuracy: 0.5437 - val_loss: 0.3168 - val_accuracy: 0.5445\n",
      "Epoch 446/1000\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.3180 - accuracy: 0.5434 - val_loss: 0.3168 - val_accuracy: 0.5448\n",
      "Epoch 447/1000\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 0.3180 - accuracy: 0.5438 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 448/1000\n",
      "2/2 [==============================] - 0s 223ms/step - loss: 0.3180 - accuracy: 0.5437 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 449/1000\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 0.3180 - accuracy: 0.5438 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 450/1000\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 0.3180 - accuracy: 0.5436 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 451/1000\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 0.3180 - accuracy: 0.5439 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 452/1000\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.3180 - accuracy: 0.5436 - val_loss: 0.3168 - val_accuracy: 0.5444\n",
      "Epoch 453/1000\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.3180 - accuracy: 0.5436 - val_loss: 0.3168 - val_accuracy: 0.5448\n",
      "Epoch 454/1000\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.3180 - accuracy: 0.5436 - val_loss: 0.3168 - val_accuracy: 0.5446\n",
      "Epoch 455/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3180 - accuracy: 0.5436 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 456/1000\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 0.3180 - accuracy: 0.5436 - val_loss: 0.3168 - val_accuracy: 0.5444\n",
      "Epoch 457/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.3180 - accuracy: 0.5436 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 458/1000\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 0.3180 - accuracy: 0.5437 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 459/1000\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 0.3180 - accuracy: 0.5437 - val_loss: 0.3168 - val_accuracy: 0.5447\n",
      "Epoch 460/1000\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.3180 - accuracy: 0.5438 - val_loss: 0.3168 - val_accuracy: 0.5444\n",
      "Epoch 461/1000\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.3180 - accuracy: 0.5436 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 462/1000\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.3180 - accuracy: 0.5437 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 463/1000\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.3180 - accuracy: 0.5437 - val_loss: 0.3167 - val_accuracy: 0.5445\n",
      "Epoch 464/1000\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.3180 - accuracy: 0.5438 - val_loss: 0.3167 - val_accuracy: 0.5448\n",
      "Epoch 465/1000\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 0.3180 - accuracy: 0.5439 - val_loss: 0.3168 - val_accuracy: 0.5445\n",
      "Epoch 466/1000\n",
      "2/2 [==============================] - 0s 224ms/step - loss: 0.3180 - accuracy: 0.5434 - val_loss: 0.3167 - val_accuracy: 0.5446\n",
      "Epoch 467/1000\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.3179 - accuracy: 0.5438 - val_loss: 0.3167 - val_accuracy: 0.5450\n",
      "Epoch 468/1000\n",
      "2/2 [==============================] - 0s 236ms/step - loss: 0.3179 - accuracy: 0.5439 - val_loss: 0.3168 - val_accuracy: 0.5443\n",
      "Epoch 469/1000\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 0.3179 - accuracy: 0.5434 - val_loss: 0.3167 - val_accuracy: 0.5448\n",
      "Epoch 470/1000\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.3180 - accuracy: 0.5441 - val_loss: 0.3167 - val_accuracy: 0.5444\n",
      "Epoch 471/1000\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.3180 - accuracy: 0.5434 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 472/1000\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.3180 - accuracy: 0.5441 - val_loss: 0.3167 - val_accuracy: 0.5444\n",
      "Epoch 473/1000\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.3179 - accuracy: 0.5435 - val_loss: 0.3167 - val_accuracy: 0.5445\n",
      "Epoch 474/1000\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.3179 - accuracy: 0.5437 - val_loss: 0.3167 - val_accuracy: 0.5448\n",
      "Epoch 475/1000\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 0.3179 - accuracy: 0.5438 - val_loss: 0.3167 - val_accuracy: 0.5446\n",
      "Epoch 476/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3179 - accuracy: 0.5438 - val_loss: 0.3167 - val_accuracy: 0.5448\n",
      "Epoch 477/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3179 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5443\n",
      "Epoch 478/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3179 - accuracy: 0.5434 - val_loss: 0.3167 - val_accuracy: 0.5448\n",
      "Epoch 479/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3179 - accuracy: 0.5440 - val_loss: 0.3167 - val_accuracy: 0.5443\n",
      "Epoch 480/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.3179 - accuracy: 0.5434 - val_loss: 0.3167 - val_accuracy: 0.5449\n",
      "Epoch 481/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3179 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5448\n",
      "Epoch 482/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3179 - accuracy: 0.5436 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 483/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3179 - accuracy: 0.5437 - val_loss: 0.3167 - val_accuracy: 0.5450\n",
      "Epoch 484/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3179 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 485/1000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.3179 - accuracy: 0.5436 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 486/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3179 - accuracy: 0.5440 - val_loss: 0.3167 - val_accuracy: 0.5444\n",
      "Epoch 487/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3179 - accuracy: 0.5435 - val_loss: 0.3167 - val_accuracy: 0.5450\n",
      "Epoch 488/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.3179 - accuracy: 0.5443 - val_loss: 0.3167 - val_accuracy: 0.5444\n",
      "Epoch 489/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3179 - accuracy: 0.5434 - val_loss: 0.3167 - val_accuracy: 0.5446\n",
      "Epoch 490/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3179 - accuracy: 0.5441 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 491/1000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.3179 - accuracy: 0.5438 - val_loss: 0.3167 - val_accuracy: 0.5444\n",
      "Epoch 492/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.3179 - accuracy: 0.5436 - val_loss: 0.3167 - val_accuracy: 0.5449\n",
      "Epoch 493/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3179 - accuracy: 0.5442 - val_loss: 0.3167 - val_accuracy: 0.5444\n",
      "Epoch 494/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3179 - accuracy: 0.5434 - val_loss: 0.3167 - val_accuracy: 0.5449\n",
      "Epoch 495/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.3179 - accuracy: 0.5441 - val_loss: 0.3167 - val_accuracy: 0.5441\n",
      "Epoch 496/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3179 - accuracy: 0.5435 - val_loss: 0.3167 - val_accuracy: 0.5448\n",
      "Epoch 497/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3179 - accuracy: 0.5443 - val_loss: 0.3167 - val_accuracy: 0.5445\n",
      "Epoch 498/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3179 - accuracy: 0.5435 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 499/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3179 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5450\n",
      "Epoch 500/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3179 - accuracy: 0.5437 - val_loss: 0.3167 - val_accuracy: 0.5445\n",
      "Epoch 501/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3179 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 502/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3179 - accuracy: 0.5436 - val_loss: 0.3167 - val_accuracy: 0.5444\n",
      "Epoch 503/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.3179 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5446\n",
      "Epoch 504/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3179 - accuracy: 0.5436 - val_loss: 0.3167 - val_accuracy: 0.5446\n",
      "Epoch 505/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3179 - accuracy: 0.5440 - val_loss: 0.3167 - val_accuracy: 0.5450\n",
      "Epoch 506/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3179 - accuracy: 0.5438 - val_loss: 0.3167 - val_accuracy: 0.5443\n",
      "Epoch 507/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3179 - accuracy: 0.5437 - val_loss: 0.3167 - val_accuracy: 0.5448\n",
      "Epoch 508/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3179 - accuracy: 0.5440 - val_loss: 0.3167 - val_accuracy: 0.5444\n",
      "Epoch 509/1000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.3179 - accuracy: 0.5436 - val_loss: 0.3167 - val_accuracy: 0.5451\n",
      "Epoch 510/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3179 - accuracy: 0.5441 - val_loss: 0.3167 - val_accuracy: 0.5444\n",
      "Epoch 511/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3179 - accuracy: 0.5436 - val_loss: 0.3167 - val_accuracy: 0.5451\n",
      "Epoch 512/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3179 - accuracy: 0.5441 - val_loss: 0.3167 - val_accuracy: 0.5444\n",
      "Epoch 513/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3179 - accuracy: 0.5437 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 514/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3179 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 515/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3179 - accuracy: 0.5438 - val_loss: 0.3167 - val_accuracy: 0.5444\n",
      "Epoch 516/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3179 - accuracy: 0.5436 - val_loss: 0.3167 - val_accuracy: 0.5451\n",
      "Epoch 517/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3179 - accuracy: 0.5441 - val_loss: 0.3167 - val_accuracy: 0.5446\n",
      "Epoch 518/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.3179 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 519/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3179 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5448\n",
      "Epoch 520/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3179 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5446\n",
      "Epoch 521/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3179 - accuracy: 0.5438 - val_loss: 0.3167 - val_accuracy: 0.5446\n",
      "Epoch 522/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3179 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5446\n",
      "Epoch 523/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3179 - accuracy: 0.5437 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 524/1000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.3179 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 525/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.3179 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 526/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5446\n",
      "Epoch 527/1000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5448\n",
      "Epoch 528/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3167 - val_accuracy: 0.5446\n",
      "Epoch 529/1000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 530/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5448\n",
      "Epoch 531/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 532/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 533/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 534/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3167 - val_accuracy: 0.5448\n",
      "Epoch 535/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 536/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3167 - val_accuracy: 0.5449\n",
      "Epoch 537/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3167 - val_accuracy: 0.5446\n",
      "Epoch 538/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 539/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 540/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3178 - accuracy: 0.5438 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 541/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 542/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 543/1000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 544/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3167 - val_accuracy: 0.5447\n",
      "Epoch 545/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 546/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 547/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 548/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 549/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 550/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 551/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 552/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 553/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 554/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5449\n",
      "Epoch 555/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 556/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 557/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 558/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 559/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 560/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 561/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5444\n",
      "Epoch 562/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5452\n",
      "Epoch 563/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3178 - accuracy: 0.5443 - val_loss: 0.3166 - val_accuracy: 0.5446\n",
      "Epoch 564/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5449\n",
      "Epoch 565/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 566/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 567/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5449\n",
      "Epoch 568/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3178 - accuracy: 0.5443 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 569/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 570/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 571/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 572/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 573/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 574/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 575/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3178 - accuracy: 0.5443 - val_loss: 0.3166 - val_accuracy: 0.5449\n",
      "Epoch 576/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 577/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 578/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 579/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 580/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5446\n",
      "Epoch 581/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 582/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3178 - accuracy: 0.5444 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 583/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 584/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3178 - accuracy: 0.5443 - val_loss: 0.3166 - val_accuracy: 0.5444\n",
      "Epoch 585/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 586/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3178 - accuracy: 0.5443 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 587/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 588/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 589/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 590/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5452\n",
      "Epoch 591/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 592/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 593/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5453\n",
      "Epoch 594/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 595/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 596/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 597/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5452\n",
      "Epoch 598/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 599/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 600/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 601/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 602/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 603/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 604/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 605/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 606/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5443 - val_loss: 0.3166 - val_accuracy: 0.5445\n",
      "Epoch 607/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5452\n",
      "Epoch 608/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3178 - accuracy: 0.5444 - val_loss: 0.3166 - val_accuracy: 0.5444\n",
      "Epoch 609/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3178 - accuracy: 0.5438 - val_loss: 0.3166 - val_accuracy: 0.5453\n",
      "Epoch 610/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3178 - accuracy: 0.5443 - val_loss: 0.3166 - val_accuracy: 0.5446\n",
      "Epoch 611/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5452\n",
      "Epoch 612/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5444 - val_loss: 0.3166 - val_accuracy: 0.5446\n",
      "Epoch 613/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3178 - accuracy: 0.5438 - val_loss: 0.3166 - val_accuracy: 0.5454\n",
      "Epoch 614/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5444 - val_loss: 0.3166 - val_accuracy: 0.5446\n",
      "Epoch 615/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5453\n",
      "Epoch 616/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3178 - accuracy: 0.5445 - val_loss: 0.3166 - val_accuracy: 0.5446\n",
      "Epoch 617/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3178 - accuracy: 0.5438 - val_loss: 0.3166 - val_accuracy: 0.5453\n",
      "Epoch 618/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3178 - accuracy: 0.5446 - val_loss: 0.3166 - val_accuracy: 0.5446\n",
      "Epoch 619/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 620/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5444 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 621/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 622/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3178 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5449\n",
      "Epoch 623/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 624/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 625/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5452\n",
      "Epoch 626/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3178 - accuracy: 0.5445 - val_loss: 0.3166 - val_accuracy: 0.5443\n",
      "Epoch 627/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5452\n",
      "Epoch 628/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3178 - accuracy: 0.5445 - val_loss: 0.3166 - val_accuracy: 0.5444\n",
      "Epoch 629/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5438 - val_loss: 0.3166 - val_accuracy: 0.5453\n",
      "Epoch 630/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3178 - accuracy: 0.5445 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 631/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3178 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 632/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 633/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3166 - val_accuracy: 0.5449\n",
      "Epoch 634/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5454\n",
      "Epoch 635/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 636/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5454\n",
      "Epoch 637/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3178 - accuracy: 0.5445 - val_loss: 0.3167 - val_accuracy: 0.5446\n",
      "Epoch 638/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5437 - val_loss: 0.3166 - val_accuracy: 0.5452\n",
      "Epoch 639/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.3178 - accuracy: 0.5446 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 640/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3178 - accuracy: 0.5438 - val_loss: 0.3166 - val_accuracy: 0.5452\n",
      "Epoch 641/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3178 - accuracy: 0.5446 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 642/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3178 - accuracy: 0.5438 - val_loss: 0.3166 - val_accuracy: 0.5452\n",
      "Epoch 643/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3178 - accuracy: 0.5446 - val_loss: 0.3166 - val_accuracy: 0.5446\n",
      "Epoch 644/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3178 - accuracy: 0.5438 - val_loss: 0.3166 - val_accuracy: 0.5454\n",
      "Epoch 645/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3178 - accuracy: 0.5447 - val_loss: 0.3167 - val_accuracy: 0.5444\n",
      "Epoch 646/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3178 - accuracy: 0.5437 - val_loss: 0.3166 - val_accuracy: 0.5453\n",
      "Epoch 647/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3178 - accuracy: 0.5447 - val_loss: 0.3166 - val_accuracy: 0.5447\n",
      "Epoch 648/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3178 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 649/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.3177 - accuracy: 0.5444 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 650/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3177 - accuracy: 0.5439 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 651/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 652/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 653/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3177 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 654/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5448\n",
      "Epoch 655/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 656/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 657/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5452\n",
      "Epoch 658/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 659/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5452\n",
      "Epoch 660/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 661/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 662/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 663/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 664/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5449\n",
      "Epoch 665/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 666/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 667/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 668/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 669/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3177 - accuracy: 0.5442 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 670/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3166 - val_accuracy: 0.5454\n",
      "Epoch 671/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3177 - accuracy: 0.5444 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 672/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 673/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5449\n",
      "Epoch 674/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 675/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3166 - val_accuracy: 0.5450\n",
      "Epoch 676/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3166 - val_accuracy: 0.5454\n",
      "Epoch 677/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5444 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 678/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 679/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 680/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 681/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3177 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5450\n",
      "Epoch 682/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 683/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 684/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3177 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 685/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 686/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 687/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 688/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5450\n",
      "Epoch 689/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 690/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 691/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 692/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5450\n",
      "Epoch 693/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 694/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 695/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5453\n",
      "Epoch 696/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 697/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3177 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 698/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 699/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 700/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3177 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 701/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 702/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 703/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 704/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 705/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 706/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 707/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 708/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 709/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3177 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 710/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 711/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 712/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 713/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 714/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 715/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 716/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3177 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 717/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5453\n",
      "Epoch 718/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 719/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3177 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 720/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 721/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5453\n",
      "Epoch 722/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 723/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5456\n",
      "Epoch 724/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3177 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 725/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 726/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5445 - val_loss: 0.3165 - val_accuracy: 0.5450\n",
      "Epoch 727/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3177 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 728/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3177 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 729/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 730/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 731/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 732/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 733/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 734/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5453\n",
      "Epoch 735/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5453\n",
      "Epoch 736/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5456\n",
      "Epoch 737/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5453\n",
      "Epoch 738/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 739/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 740/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5453\n",
      "Epoch 741/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5453\n",
      "Epoch 742/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 743/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 744/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 745/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 746/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 747/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 748/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3177 - accuracy: 0.5439 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 749/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3177 - accuracy: 0.5447 - val_loss: 0.3166 - val_accuracy: 0.5451\n",
      "Epoch 750/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3177 - accuracy: 0.5438 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 751/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5445 - val_loss: 0.3165 - val_accuracy: 0.5449\n",
      "Epoch 752/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3176 - accuracy: 0.5439 - val_loss: 0.3165 - val_accuracy: 0.5453\n",
      "Epoch 753/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3176 - accuracy: 0.5445 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 754/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 755/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 756/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 757/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 758/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 759/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 760/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 761/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 762/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5453\n",
      "Epoch 763/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5457\n",
      "Epoch 764/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5450\n",
      "Epoch 765/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 766/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5453\n",
      "Epoch 767/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 768/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 769/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 770/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 771/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 772/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 773/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 774/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 775/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5458\n",
      "Epoch 776/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5457\n",
      "Epoch 777/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 778/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 779/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5458\n",
      "Epoch 780/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 781/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 782/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 783/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3176 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 784/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 785/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 786/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 787/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 788/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5458\n",
      "Epoch 789/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 790/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 791/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 792/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5456\n",
      "Epoch 793/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 794/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5459\n",
      "Epoch 795/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3176 - accuracy: 0.5445 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 796/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 797/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 798/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5458\n",
      "Epoch 799/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 800/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5457\n",
      "Epoch 801/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 802/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5456\n",
      "Epoch 803/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 804/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5457\n",
      "Epoch 805/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 806/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 807/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 808/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 809/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 810/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 811/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5458\n",
      "Epoch 812/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5445 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 813/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5457\n",
      "Epoch 814/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5453\n",
      "Epoch 815/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.3176 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 816/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 817/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5456\n",
      "Epoch 818/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 819/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 820/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 821/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5456\n",
      "Epoch 822/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 823/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 824/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 825/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 826/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5453\n",
      "Epoch 827/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5458\n",
      "Epoch 828/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3176 - accuracy: 0.5445 - val_loss: 0.3165 - val_accuracy: 0.5450\n",
      "Epoch 829/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5457\n",
      "Epoch 830/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5452\n",
      "Epoch 831/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5457\n",
      "Epoch 832/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 833/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5457\n",
      "Epoch 834/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3176 - accuracy: 0.5445 - val_loss: 0.3165 - val_accuracy: 0.5448\n",
      "Epoch 835/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5458\n",
      "Epoch 836/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 837/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 838/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.3176 - accuracy: 0.5446 - val_loss: 0.3165 - val_accuracy: 0.5447\n",
      "Epoch 839/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5457\n",
      "Epoch 840/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5446 - val_loss: 0.3165 - val_accuracy: 0.5447\n",
      "Epoch 841/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5438 - val_loss: 0.3165 - val_accuracy: 0.5453\n",
      "Epoch 842/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3176 - accuracy: 0.5445 - val_loss: 0.3165 - val_accuracy: 0.5447\n",
      "Epoch 843/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5457\n",
      "Epoch 844/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3176 - accuracy: 0.5445 - val_loss: 0.3165 - val_accuracy: 0.5449\n",
      "Epoch 845/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5458\n",
      "Epoch 846/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3176 - accuracy: 0.5444 - val_loss: 0.3165 - val_accuracy: 0.5451\n",
      "Epoch 847/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 848/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5450\n",
      "Epoch 849/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3164 - val_accuracy: 0.5452\n",
      "Epoch 850/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3175 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 851/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3175 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 852/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3175 - accuracy: 0.5443 - val_loss: 0.3165 - val_accuracy: 0.5450\n",
      "Epoch 853/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3175 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5456\n",
      "Epoch 854/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3176 - accuracy: 0.5446 - val_loss: 0.3165 - val_accuracy: 0.5447\n",
      "Epoch 855/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3176 - accuracy: 0.5442 - val_loss: 0.3164 - val_accuracy: 0.5458\n",
      "Epoch 856/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3176 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5457\n",
      "Epoch 857/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 858/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5448\n",
      "Epoch 859/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5442 - val_loss: 0.3164 - val_accuracy: 0.5457\n",
      "Epoch 860/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3165 - val_accuracy: 0.5448\n",
      "Epoch 861/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3175 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5457\n",
      "Epoch 862/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3176 - accuracy: 0.5446 - val_loss: 0.3164 - val_accuracy: 0.5449\n",
      "Epoch 863/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3175 - accuracy: 0.5442 - val_loss: 0.3164 - val_accuracy: 0.5457\n",
      "Epoch 864/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5449\n",
      "Epoch 865/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3175 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 866/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5446 - val_loss: 0.3165 - val_accuracy: 0.5447\n",
      "Epoch 867/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3175 - accuracy: 0.5442 - val_loss: 0.3164 - val_accuracy: 0.5455\n",
      "Epoch 868/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3175 - accuracy: 0.5446 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 869/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 870/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3175 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5450\n",
      "Epoch 871/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5452\n",
      "Epoch 872/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 873/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3175 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5455\n",
      "Epoch 874/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3175 - accuracy: 0.5446 - val_loss: 0.3164 - val_accuracy: 0.5448\n",
      "Epoch 875/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3175 - accuracy: 0.5441 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 876/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3175 - accuracy: 0.5446 - val_loss: 0.3164 - val_accuracy: 0.5447\n",
      "Epoch 877/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3175 - accuracy: 0.5441 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 878/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3175 - accuracy: 0.5447 - val_loss: 0.3165 - val_accuracy: 0.5446\n",
      "Epoch 879/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5440 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 880/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5447 - val_loss: 0.3164 - val_accuracy: 0.5447\n",
      "Epoch 881/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5442 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 882/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5447 - val_loss: 0.3165 - val_accuracy: 0.5445\n",
      "Epoch 883/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3176 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 884/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3175 - accuracy: 0.5449 - val_loss: 0.3165 - val_accuracy: 0.5447\n",
      "Epoch 885/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3175 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 886/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3176 - accuracy: 0.5447 - val_loss: 0.3164 - val_accuracy: 0.5447\n",
      "Epoch 887/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5442 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 888/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5446 - val_loss: 0.3165 - val_accuracy: 0.5447\n",
      "Epoch 889/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3175 - accuracy: 0.5441 - val_loss: 0.3165 - val_accuracy: 0.5454\n",
      "Epoch 890/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5447 - val_loss: 0.3165 - val_accuracy: 0.5447\n",
      "Epoch 891/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5442 - val_loss: 0.3165 - val_accuracy: 0.5455\n",
      "Epoch 892/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5447 - val_loss: 0.3165 - val_accuracy: 0.5447\n",
      "Epoch 893/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3175 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 894/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5448\n",
      "Epoch 895/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3175 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 896/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5448\n",
      "Epoch 897/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 898/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 899/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5455\n",
      "Epoch 900/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5449\n",
      "Epoch 901/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5452\n",
      "Epoch 902/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5450\n",
      "Epoch 903/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 904/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5450\n",
      "Epoch 905/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5450\n",
      "Epoch 906/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 907/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5448\n",
      "Epoch 908/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5449\n",
      "Epoch 909/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 910/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5449\n",
      "Epoch 911/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5450\n",
      "Epoch 912/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5452\n",
      "Epoch 913/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 914/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 915/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5449\n",
      "Epoch 916/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 917/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5452\n",
      "Epoch 918/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 919/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5453\n",
      "Epoch 920/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 921/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5450\n",
      "Epoch 922/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5450\n",
      "Epoch 923/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 924/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.3175 - accuracy: 0.5446 - val_loss: 0.3164 - val_accuracy: 0.5448\n",
      "Epoch 925/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.3175 - accuracy: 0.5442 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 926/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.3175 - accuracy: 0.5448 - val_loss: 0.3164 - val_accuracy: 0.5444\n",
      "Epoch 927/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.3175 - accuracy: 0.5441 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 928/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5448 - val_loss: 0.3164 - val_accuracy: 0.5446\n",
      "Epoch 929/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 930/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5448\n",
      "Epoch 931/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5442 - val_loss: 0.3164 - val_accuracy: 0.5452\n",
      "Epoch 932/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5448 - val_loss: 0.3164 - val_accuracy: 0.5445\n",
      "Epoch 933/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5442 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 934/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5447 - val_loss: 0.3164 - val_accuracy: 0.5448\n",
      "Epoch 935/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 936/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5446 - val_loss: 0.3164 - val_accuracy: 0.5446\n",
      "Epoch 937/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5455\n",
      "Epoch 938/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3175 - accuracy: 0.5448 - val_loss: 0.3164 - val_accuracy: 0.5447\n",
      "Epoch 939/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5455\n",
      "Epoch 940/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3175 - accuracy: 0.5447 - val_loss: 0.3164 - val_accuracy: 0.5447\n",
      "Epoch 941/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 942/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3175 - accuracy: 0.5447 - val_loss: 0.3164 - val_accuracy: 0.5447\n",
      "Epoch 943/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3175 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 944/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3175 - accuracy: 0.5446 - val_loss: 0.3164 - val_accuracy: 0.5447\n",
      "Epoch 945/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 946/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5446 - val_loss: 0.3164 - val_accuracy: 0.5446\n",
      "Epoch 947/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 948/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5447 - val_loss: 0.3164 - val_accuracy: 0.5447\n",
      "Epoch 949/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 950/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3175 - accuracy: 0.5446 - val_loss: 0.3164 - val_accuracy: 0.5446\n",
      "Epoch 951/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 952/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.3175 - accuracy: 0.5449 - val_loss: 0.3164 - val_accuracy: 0.5444\n",
      "Epoch 953/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3175 - accuracy: 0.5442 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 954/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5448 - val_loss: 0.3165 - val_accuracy: 0.5446\n",
      "Epoch 955/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5442 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 956/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5449 - val_loss: 0.3164 - val_accuracy: 0.5446\n",
      "Epoch 957/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5441 - val_loss: 0.3164 - val_accuracy: 0.5450\n",
      "Epoch 958/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5449 - val_loss: 0.3165 - val_accuracy: 0.5444\n",
      "Epoch 959/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5442 - val_loss: 0.3164 - val_accuracy: 0.5452\n",
      "Epoch 960/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5447 - val_loss: 0.3164 - val_accuracy: 0.5448\n",
      "Epoch 961/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5447 - val_loss: 0.3164 - val_accuracy: 0.5452\n",
      "Epoch 962/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 963/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3175 - accuracy: 0.5448 - val_loss: 0.3164 - val_accuracy: 0.5448\n",
      "Epoch 964/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.3175 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5453\n",
      "Epoch 965/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5447 - val_loss: 0.3164 - val_accuracy: 0.5450\n",
      "Epoch 966/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5452\n",
      "Epoch 967/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3174 - accuracy: 0.5446 - val_loss: 0.3164 - val_accuracy: 0.5453\n",
      "Epoch 968/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5446 - val_loss: 0.3164 - val_accuracy: 0.5447\n",
      "Epoch 969/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 970/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5447 - val_loss: 0.3164 - val_accuracy: 0.5447\n",
      "Epoch 971/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5452\n",
      "Epoch 972/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.3174 - accuracy: 0.5448 - val_loss: 0.3164 - val_accuracy: 0.5448\n",
      "Epoch 973/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 974/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5448 - val_loss: 0.3164 - val_accuracy: 0.5447\n",
      "Epoch 975/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5453\n",
      "Epoch 976/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5448 - val_loss: 0.3164 - val_accuracy: 0.5447\n",
      "Epoch 977/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3175 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5453\n",
      "Epoch 978/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3174 - accuracy: 0.5447 - val_loss: 0.3164 - val_accuracy: 0.5447\n",
      "Epoch 979/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3174 - accuracy: 0.5444 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 980/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3174 - accuracy: 0.5448 - val_loss: 0.3164 - val_accuracy: 0.5448\n",
      "Epoch 981/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3174 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5452\n",
      "Epoch 982/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3175 - accuracy: 0.5447 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 983/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3174 - accuracy: 0.5447 - val_loss: 0.3164 - val_accuracy: 0.5454\n",
      "Epoch 984/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3174 - accuracy: 0.5447 - val_loss: 0.3164 - val_accuracy: 0.5450\n",
      "Epoch 985/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3174 - accuracy: 0.5446 - val_loss: 0.3163 - val_accuracy: 0.5453\n",
      "Epoch 986/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3174 - accuracy: 0.5446 - val_loss: 0.3163 - val_accuracy: 0.5448\n",
      "Epoch 987/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3174 - accuracy: 0.5446 - val_loss: 0.3163 - val_accuracy: 0.5450\n",
      "Epoch 988/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3174 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5453\n",
      "Epoch 989/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3174 - accuracy: 0.5449 - val_loss: 0.3164 - val_accuracy: 0.5448\n",
      "Epoch 990/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5442 - val_loss: 0.3164 - val_accuracy: 0.5452\n",
      "Epoch 991/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3175 - accuracy: 0.5450 - val_loss: 0.3164 - val_accuracy: 0.5447\n",
      "Epoch 992/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5442 - val_loss: 0.3164 - val_accuracy: 0.5452\n",
      "Epoch 993/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5449 - val_loss: 0.3164 - val_accuracy: 0.5446\n",
      "Epoch 994/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3174 - accuracy: 0.5443 - val_loss: 0.3164 - val_accuracy: 0.5453\n",
      "Epoch 995/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3175 - accuracy: 0.5450 - val_loss: 0.3164 - val_accuracy: 0.5447\n",
      "Epoch 996/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.3174 - accuracy: 0.5445 - val_loss: 0.3164 - val_accuracy: 0.5451\n",
      "Epoch 997/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3174 - accuracy: 0.5448 - val_loss: 0.3164 - val_accuracy: 0.5448\n",
      "Epoch 998/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.3174 - accuracy: 0.5446 - val_loss: 0.3163 - val_accuracy: 0.5453\n",
      "Epoch 999/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3174 - accuracy: 0.5447 - val_loss: 0.3163 - val_accuracy: 0.5454\n",
      "Epoch 1000/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3174 - accuracy: 0.5448 - val_loss: 0.3163 - val_accuracy: 0.5450\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_split=0.1, batch_size = 100000, epochs = 1000, callbacks = [callback], verbose=1) #np.array(x), [np.array(y),a,a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnwAAAFnCAYAAAA8FJSTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dW4wc2X3f8d+/e24ccjhXcrmSNtodMY5gxJDE3QWixEpkazYvwiJBwpUe8pLAFpkAgZ+cpRfIcxRukAS5AAopGIHfJC2FIFlEQUyuFSSxYYcXKZGsGHZ2dLMl7S7J6blPd0/3Pw9VPVPd7J7pmekzp7bm+wEa3V1VXXXYh8P58V91Tpm7CwAAAMVVit0AAAAAhEXgAwAAKDgCHwAAQMER+AAAAAqOwAcAAFBwBD4AAICCI/ABwD7M7IqZvW1mS2bm6ePSHtvPd2zr6fupkPsEgF6MefgAoD9puLovaV7SA3d/fp/tL0t6Q9JL7n7nuPYJAJ2o8AHAwdyS9EDSJTO7steG7n5L0p0+glmIfQLADgIfABzMI0mvpK+v97H9YqR9AsAOAh8AHJC7L0q6KWnKzPoJaFH2CQAtBD4AOJxrkiqSXjWz+RzvEwAIfABwGO5eURLQJOlGXvcJABKBDwAOzd1vKhlssZCOns3lPgGAwAcAR/OF9PnLOd8ngBOMwAcAR+DuDzT4ARwD3yeAk43ABwBHxwAOALlG4AOAI2IAB4C8I/ABwACkgy0WlQy2WMjrPgGcTAQ+ABic1t0yBlmRC7FPACcMgQ8ABiQdbHFL0ryZvZrXfQI4eQh8ADBYrSlVrg9wsEWIfQI4QQh8ADBAHYMtBjVNy8D3CeBkIfABwIC5++tKBltcljSQilyIfQI4OQh8ANC/GUmzfW57NeI+AaANgQ8A+ndN0mUzm9pvQ3e/o2SwRYx9AkAbAh8A7MPMrpjZkqQrSk6nLpnZ7T4+2rpbxrHsEwB6MXeP3QYAAAAERIUPAACg4Ah8AAAABUfgAwAAKDgCHwAAQMER+AAAAApuKHYD8m5ubs6fffbZoMfY3t7W0BBdkTf0S/7QJ/lEv+QPfZJPx9Ev9+/ff+ju5zqX87dhH88++6zu3bsX9BgPHz7U3Nxc0GPg4OiX/KFP8ol+yR/6JJ+Oo1/M7IfdlnNKFwAAoOAIfAAAAAVH4AMAACg4Ah8AAEDBEfgAAAAKjsAHAABQcAQ+AACAgiPwAQAAFByBDwAAoOAIfLH9h3+gM2/9RuxWAACAAuPWaj2Y2cuSXr548WLYAy39QKVGI+wxAADAiUaFrwd3f9Pdr0xOToY9kJnMwx4CAACcbAS+6EwSiQ8AAIRD4IvNCHwAACAsAl8eOIEPAACEQ+CLjQofAAAIjMAXnVHhAwAAQRH4YqPCBwAAAiPwRWfkPQAAEBSBLzaz2C0AAAAFR+DLBUp8AAAgHAJfdFzDBwAAwiLwxWaM0gUAAGER+KKjwgcAAMIi8MVGhQ8AAARG4IvOZFT4AABAQAS+2JiWBQAABEbgi45TugAAICwCX2zcWg0AAARG4IuOCh8AAAiLwBcbFT4AABAYgQ8AAKDgCHx5wCldAAAQEIEvNk7pAgCAwAh80TEPHwAACIvAFxu3VgMAAIER+KLjlC4AAAiLwBcbFT4AABAYga8HM3vZzG4uLy+HPpKo8AEAgJAIfD24+5vufmVycjLsgcxkVPgAAEBABL7oqPABAICwCHyxMQ8fAAAIjMAXnZH3AABAUAS+2KjwAQCAwAh8AAAABUfgi455+AAAQFgEvtg4pQsAAAIj8EVH4AMAAGER+GLj1moAACAwAl90VPgAAEBYBL7YyHsAACAwAl90JD4AABAWgS82ruEDAACBEfiiMxkVPgAAEBCBLzbm4QMAAIER+KLjlC4AAAiLwBebWewWAACAgiPw5QIVPgAAEA6BLzoj7wEAgKAIfLExaAMAAARG4IuOQRsAACAsAl9sVPgAAEBgBL7oCHwAACAsAl9s3FoNAAAERuCLjgofAAAIi8AXmzEtCwAACIvAFx0VPgAAEBaBLzYzGYEPAAAERODLAwZtAACAgAh8PZjZy2Z2c3l5OXZTAAAAjoTA14O7v+nuVyYnJ8MeiImXAQBAYAS+6JiHDwAAhEXgi40KHwAACIzAFx3z8AEAgLAIfLFR4QMAAIER+KIj8AEAgLAIfLEZgzYAAEBYBL7oqPABAICwCHyxUeEDAACBEfii4166AAAgLAJfbGaxWwAAAAqOwBcdgQ8AAIRF4MsLruMDAACBEPhia53SJfABAIBACHzRtU7pEvgAAEAYBL7YqPABAIDACHzRUeEDAABhEfhi28l7BD4AABAGgS86KnwAACAsAl9sXMMHAAACI/BFR4UPAACEReCLjQofAAAIjMAXHRU+AAAQFoEvNuNeugAAICwCX15wShcAAARC4IuOU7oAACAsAl9sDNoAAACBEfiio8IHAADCIvDFRoUPAAAERuCLjgofAAAIi8AXGxU+AAAQGIEvOubhAwAAYZ3owGdmV8xsIXIjkmcqfAAAIJATHfgk3ZM0FbcJXMMHAADCihb4zOySmV02s8tH2MeCmd3uWHY5Xf7q0Vt5DKjwAQCAwGJW+F5z91uS5s1s/jA7cPc72fet8Jgur7RO17aCZeYRuarXDYEPAACEMRTjoGZ2RdJtM5t399e7rL8kSe7+ILP919y9ss+uX5T01fT1oqRLku6kwbKbBUmzZnanc99m9rKkly9evNjvHwsAACCXYlX4PpI+HpvZjc6KWxr05tPTvleUhLb9wp705PV4s3tt7O6vu/u1bvt29zfd/crk5GQfhz0CTukCAIDAYp7SfTsNWvclXelcmVblrqavF/vcZ0XSzMBaeCwYtAEAAMKKFfjuZl5PKQlqbdLr8W6kr/u9xu+udqt885Ju77FtPlDhAwAAgUUJfGn1bqo1qMLdb2bXp9fwVdz9QbpuodtAizQUvpAZrNEaBNLa753Oz+QPFT4AABBWlEEbUnL9XPryiVDWGqyReX+zc5t0+S1JtzqWPTEIJNeo8AEAgMBO+sTLOUCFDwAAhEXgi40KHwAACIzAFx0VPgAAEBaBLzYqfAAAIDACX3RU+AAAQFgEvtio8AEAgMAIfNHZ/psAAAAcAYEvN6jwAQCAMA488bKZnW29dveVdNnfkvSipNvu/juDa94JwCldAAAQ2GEqfK9Lui5pQZLM7EuSrkr6mqTpNPyhb5zSBQAAYR3m1mq33f3rkmRmz0m6Imk6rfZ9y8z+9iAbWHhU+AAAQGCHqfAtZV4vSPpW69Rul/XYF9OyAACAsI46aOOypK90LJs+4j5PFip8AAAgsMOc0p02s1+W9LySgRqvSDund1+VdGNwzTtJCHwAACCMA1f40uv3Wuchn3f3FTP7hJJr+ZYlvTDA9hUfFT4AABDYYadluSvpnrsvp4ufUxICf5tpWQ6Ka/gAAEBYR5mW5TNS27QsXxXTshwcFT4AABAY07JER4UPAACExbQssVHhAwAAgTEtCwAAQMExLUt0nNIFAABhDXJalqtiWpaD45QuAAAI7DAVPrn7W2Z2V9JCOkhjUdI/6biWD32hwgcAAMI6VOAzsy8omZplMbP4DTN71d3/+UBadlJQ4QMAAIEd+JSumX1G0pS7z7j7C62HpFlJ55iH76Co8AEAgLAOM0r3OXf/Z50L3b3i7r+hJPihX1T4AABAYIcJfI/3Wf/oMA05uajwAQCAsA4T+Gb2WT9/mIacWDsVvrjNAAAAxXWYwPd9M/uimU1kF5rZWTP7oqQHg2naSUGFDwAAhHXgUbrplCzTkn5oZo8kVSRNKan8XXP33xlwG4uNa/gAAEBgh52H75akW+mI3Xkl07Pcc/flQTbuZKDCBwAAwjpU4Gtx97ckvZVdZmYfd/dvH6lVAAAAGJjDXMO3n9cC7LO4dgp8VPgAAEAYe1b4zKypg51rtANuD07pAgCAwPar8N2RNOPu5T4fJUlfP4Z2FweDNgAAQGD7Bb6rhxiIce2wjTmZqPABAICw9gx87v79g+7wMJ850ajwAQCAwEIM2igEM3vZzG4uL4eeaYYKHwAACIvA14O7v+nuVyYnJ4MeZzvNeduNZtDjAACAk4vAF9k3vvOOJOmbf/SzyC0BAABFReCL7Iebw5Kk4Ro3KQEAAGEQ+CL76faEJGm6WYncEgAAUFQEvsh+UjutppsmmkuxmwIAAAqKwBfZ0lZTjzWh0a1HsZsCAAAKisAX2cpmXY/8rIa3HsZuCgAAKCgCX2TLm3UtaUJDVa7hAwAAYRD4Ivvk/KzqXpZ5I3ZTAABAQRH4Ivu1z/x5uUxqMvEyAAAIg8AXWbkkNVSSROADAABhEPgiMzM1VZI5gQ8AAIRB4IusbKamTOIaPgAAEAiBL7JSWuETFT4AABAIgS+yUklqyjilCwAAgiHwRVbaOaVL4AMAAGEQ+CLjlC4AAAiNwBdZckqXUboAACAcAl9kJTM1CHwAACAgAl9kZbPkThsEPgAAEAiBL7KSmZrOKF0AABAOgS+yUnprNePWagAAIBACX2RMywIAAEIj8EVWMpMzaAMAAARE4IuMU7oAACA0Al9krVO6VPgAAEAoBL7IyumdNgh8AAAgFAJfZGaiwgcAAIIi8EVmrUEbXMMHAAACIfDlQNNKknvsZgAAgIIi8OWAy1RSI3YzAABAQRH4csCtLKPCBwAAAiHw5YDLuIYPAAAEQ+DLAbeSTM51fAAAIAgCXw54qxuYmgUAAARA4MsBt7QbmgzcAAAAg0fgywVLnqjwAQCAAAh8OdC0cvKCwAcAAAIg8OWBtSp8nNIFAACDR+DLgSaDNgAAQEAEvjwwAh8AAAiHwJcHO6N0CXwAAGDwCHw5wCldAAAQEoEvB3bm4WPQBgAACIDAlwNmzMMHAADCIfDlQFPMwwcAAMIh8OVBq8LHrdUAAEAAJzrwmdkVM1uI3Q7nThsAACCgEx34JN2TNBW7EeIaPgAAEFD0wGdm14/w2QUzu92x7HK6/NWjt+6YMPEyAAAIKGrgS0+nzh/28+5+p2N/lzPLK63TtWkIzD7iV/UynMAHAAACGop1YDObl7TYY90lSXL3B+n7K5K+5u6VfXb7oqSvpq8XJV2SdMfdb/XYfkHSrJnd6WPf4ezcaYNBGwAAYPCiBT5J8+5+Z2cOugx3f5BW4iTpBSWhrZ9A1lm5m91rY3d/vdc6M3tZ0ssXL17s47BH40zLAgAAAopyStfMFjpPx3ZKq3JX09ddK4FdVCTNHLF5reO/6e5XJicnB7G7vaWh97f/96J+65vfCX88AABwosSq8D1Or6+bkjRvZpdap29b0uvxbkh6wczm+wx9d7Vb5ZuXdHuPbfMjnZblr/3e39OobUufruyO3AUAADiiKBU+d3+QVvhm1GValPQavkq63U1JC90GWqSh8IXMYI1bSgLkQvp+zypiXngp6YZR204W/OTBHlsDAAAcTMxr+JSGuZtdlj/osl23z9+SdKtjWc/r8vKqZB25e/nPpA8+H6cxAACgcKLPwwfJOgPfdjVOQwAAQCER+PKgVG5/v70Zpx0AAKCQCHw5YKX2bvD6VqSWAACAIiLw5UHHKd1GbSNSQwAAQBER+HKg1FHh265R4QMAAIND4MuDjmv4GlUqfAAAYHAIfHlQGm5726gxaAMAAAwOgS8HmtY+HWKDU7oAAGCACHx5UG6v8HmdCh8AABgcAl8elNorfE0CHwAAGCACXx50XMOnbU7pAgCAwSHw5YCXO25pzMTLAABggAh8OWAdFT6jwgcAAAaIwJcDTwS+RjVSSwAAQBER+PKgvDvx8pqPyRpU+AAAwOAQ+PIgMy3LisZVosIHAAAGiMCXB5lTust+WmUCHwAAGCACXw4MZU7prigNfO98T3KP2CoAAFAUBL4cKJds5/WKn9ap7Yr0pU9Kv/uvIrYKAAAUBYEvB8qZXli307tv/vi/Hn9jAABA4RD4cqBkuxW+9VIm8K2/F6E1AACgaAh8OTCUOaW7UTqz83p79d0YzQEAAAVD4MuB7DV8G+WJ3RWNWoTWAACAoiHw5UA28FXLu6d0XdZtcwAAgAMh8OVAJu+pWR7beV1uVJmaBQAAHBmBLwey1/A1y6M7r0tqSLX1GE0CAAAFQuDLgewoXc9U+CRJ1dVjbg0AACgaAl8ONDOnbasabl9ZXTnm1gAAgKIh8OVArbEb+KxZb1/5s+9IP757zC0CAABFQuDLgdp2c+f1qac/Kkn6N9t/M1nw9V+RfnNBajZiNA0AABQAgS8Hao3dwPd3/vpf0S+d+Y/69uRC+0bvfPeYWwUAAIqCwJcDtYbrE1v/Tv/iY/9Zz8yM65u//mk9e/Hn2zf60R/EaRwAAHjfI/DlwKcvTmtJZ/XZT35sZ9nTc9M7r1f8lBp/el/6n/9Sevz9GE0EAADvY0OxGwDpQ1Nj+sE//Wz7sulxvV7/vD5a+pFmtKJf/M5XpO9I+v0vSX/1H0mjZ6VfeEUqkdkBAMDeCHw5dWFyTH+/8Tf0qfk5/dzib+kXy3+omg9pZO0d6Ru/nmz0e/9aOjUtfeATyfPYpDTxtDQ+I52aSZ7HpqQy3QwAwElGEsipjz8zpX//d1/UX744q5//x++oriF9o/GXdLH0ZxpRXR8dfaRf2fh9lbeWNPOjL6nUOZ1L1thkEgjHZ6XT56TTc+nzOen0+fb347MERAAACobf7Dn2Sx89L0l67bN/Ub/7/y7oNxd+Tl+5+2N9/JlJ3fzvi7r53i9LkkZUl8k1qXU9ZUuaLa3pg6Nb+uDohp4a3tRcaV3TtqbJjVVNrP5Q4/VvaaT6uEdItKQyuBMI55JQOHEhqR5OPJU8n3kqCZGZu4QAAIB8IvC9D/zqp+b1q5+alyR97JkpSdLnXnhGy5t1rW5t66fLWzo1XNZPljf108qmHq3X9HCtpm+vVfV4vZa+r2p1azuzV9dZbWjOlnWhvKrnTm3qgyNr+sDQqs6VVjW7vazJpYrOvPdjnao91FB97cmGlUfbA2BnIJx4OgmKBEMAAKIi8L1PmZmmxkc0NT6iZ2bGJUm/8KHJPT9T3W4kAXAtCYCP1mp6tN56runuWlWP0vXvrVXbJ4TWls5bRedV0YdHVvTc2Kr+3NCKLjQrOre8pMnH39WZ2jc1XO9y79/yaBoAL7Q/zmTfP00wBAAgEALfCTI6VNbTk6f09OSpfbd1d63XGnq0VtXDtZoeZaqF761W9b3Vqr65sqV3Vrf0zspuOBxTNQ2GS5ofW9X86Ko+NLyip1XR3OqSJpe+q9O1/6bhepd7BJdH0hD4VHvFsBUMW6FxfI7RyQAAHACBD12Zmc6MDunM6JA+PHt6z23dXcubdb2zUtU7K1t6Z2VL765W9bPlLT1Y2dJ/Wa3q3XRZo5ncN3hUNZ23JV2wJc2PrWl+dFXPDK/oglU0t/pYZyv/V6dr/0PDteUujStLZ87vBsC250xIPHNeKg+H+HoAAHhfIfDhyLKnl//ChYme2zWbrkfrtTQQbmUCYlX/a2VL/yl9/Wi9Kk9yoUZV0zlb1gVb0kdOrem50VV9aHhVF0oVzW4uaXLt+zpdu6uR6mOZvLNluyOTx9NpasZn0ylrZjvep4/RSaqHAIDCIfDh2JRKpnMTozo3MSqp9/WG9UZTD9eqO4GwVR18d6WqP1jd0pur1SeC4ZC2NadlnbeK5k+t7Z5KLi1rur6iicqqzjz6nsbqyxqpLcm80f3gVk6nsJnR5PCENHE+nddweme5Ts08+XpkfPBfGAAAA0LgQ+4Ml0t9XWu43Wjq0XpN765U9e7qbih8d3VL/2elqrdWt/TealVLG3Vt1rMBLxmhPGVrmtGqPjC6oQ+NbOqp4Q2dK69pxtY0VV/V6a1lTay+rfHtBxqtL6vc2OrdmKGxjiC4T0BsbcMpZwDAMSDw4X1rqFzSU2fH9NTZMe1VMZSkrXpDSxs1PV6vaWm9rqWN2s77ykZdP12v6Y8261rerGslfV7eqKmROUs8qpqmtKZpW0vCoq3p6ZENnR/a1Lmhdc021zW1vqbJ9WWdaf5Y441VjdWXVfLt3g0bmZDGp/cIhTPtp6PH56SR04xmBgAcCIEPJ8LYcP8jlFvee+89nTo7nYa/NARmA2H6+MPN7uu2my7JdUabmrJ1TWk1CYtKwuJTwxs619zQ3Ma6prfWNLn0M000/0SnGysaa6x2uSYxVR5Nr02c3Q2B47PJJNnZYNhadmqGu6cAwAnHbwGgh+xI5Q9O9R8UpWTk8kat0RYMO0Phzzbr+uMu6yubdTWbDZ1VcoeUaa1qytY0ayua1qou+LrOb6zp/Naqph+/o0n/E000lnWq2WVy7FZ7xqZk42lAbN13eedxtv39aGb5yGlpeJyKIgC8zxH4gADMTKdHh3R6dEgfOERYXKtuq7JRTx6bNS1tJKeYlzbq+tONur67UVNlMzk1vbyRPG9UN3XWVzVj6UOrmrZVzWpF09uremprTecrq5q0R5rQhs74usaa6yqrxwCWVntk8uFT0vBp2ci4bORMMkhleHw3EA6fSq5jHBrdfS4PS6XhZH7F8lD76/JI+j59beU0VFr35/R1eXlZqk132aa09+elPrbZaz9K21Ha5/M9tiEwA4iMwAfkjJlpYmxYE2PDemam/881m67VrW1VNpPrEpc2alrerGtpPQmHP9ioq5KGxspm8rqyXtN2dU0Tvq6ztqEJbeisbeiskvfjqmrcqjq1XdXpzS2dsqpOW1VnSjWdsRWdtqpOqapR1TWiuka8pmGv7RsiD2s6yF6Pj3eEQusreKqPbfYPy32H051jduoRWs00tb0tDQ3tvW3X0Gt7bJMJ2tm2tW233/s99tvtc31tu9fyUOu0x7run5uo1aWRkR6f6/P7Oey6w/y5rfN9pm+69VPP/fVo657bZnhTck+ezSQrS6UhqVTuvs9+99vyiV/rf9sBI/ABBVEqmSbHhzU5PqwPz/b/uUbTtbKZjGTeqDW0lT5v1hvarG3vLN+sNfQ4Xf7kdu3Lq9Wq6vWatus1lb2ukm9ryBsatm0NqaERJc/D2taIbaukpiyJQ+nz7us0JqXbtK9XZrvSzvLsuvZ9lsx3ro3sdTzr2E9/6/doq3VvT6lLW0tPtLXb8Vv77f6dtNbt7GePtibH69hHt9+TPa4n3d1095dh57a9f/Wn35dl3ydb9Oqj7Oez23Rra+d2vV63R5bs+u7LJX8yo+x7LMv8+fb+jp78rru3ae/jJWcKzLr1Sf/H7vV9ZPdjT7zur40uybxXX6U/F5ZuY5J1+SvY8zrnrn/GXttmt5HcWj81ybKSN1VSQyU1e3yu189G9+XbH/uHe7YjJAIfcMKVS6bp0yPBq2furkbT1XBXsyk10vfNnWW+s8xdmW13lz9+XNHE5GTyudbnM/trNr3r55Jtkypo071j2932tbdX8vQf7dYqz6xL3revz/5Zu33GJTV77LO1wPfYf6/jZ59af44n2qSO911+H7me/A720jrW5taWTo2N7XuM/fa/fxv3b9+gj9n5+b3eZv8OdfZVNz3jSo8P7dkdHSur1apGR0efbH/bcQ62PDlM+9/t3W2963fbFig7qnglk0pmO/tMbsTkOz8r7q6mP7mfg9jdT//fQ/Z99vvb8+9On5/5t6V4sYvAB+BYmJmGynakf3QejtQ1Nzc1sDZhMB4+fKi5ubnYzUAGfZJPDx8+jHZs7iEFAABQcAQ+AACAgiPwAQAAFByBDwAAoOAIfAAAAAVH4AMAACg4Ah8AAEDBEfgAAAAKjsAHAABQcAQ+AACAgrNe9+xDwszek/TDwIeZkxTvfivohX7JH/okn+iX/KFP8uk4+uXD7n6ucyGBLwfM7J67vxC7HWhHv+QPfZJP9Ev+0Cf5FLNfOKULAABQcAQ+AACAgiPw5cPN2A1AV/RL/tAn+US/5A99kk/R+oVr+AAAAAqOCh8AAEDBEfgAAAAKjsAHAABQcEOxG3BSmdklSQuSFiXNSFp09ztxW1VsZnZZyXf9vKR5STfc/VbHNvv2C30XhplNSbru7lc7ltMnEaQ/L/Pp20VJlex3Sr8cPzNbkHQpfTsr6W13v9mxDf0SkJldl/RVd3/QZd1Avvtg/ePuPI75oeQf0Tc6lr0h6VLsthX1IemypPnM+ylJb0t69SD9Qt8F7aM3uny39EmcvnhV0pXM+8tKwgX9Eq9PFiQtdFnGv2Hhv/t5STckXZe01NkPg/zuQ/ZP9C/yJD7SvzidP7iXJN2O3baiPrK/vDLLLif/5+m/X+i7YP2zkP5j2vkPHX1y/H0xL+l+x7Kp7HdMv0Tplzf2W06/HEs/vN0j8A3kuw/ZP0zLEoGZLUl63t0XM8umJC25u8VrWTGZ2bySH9LnPVOG71zeT7/Qd4OXfn8vKAkaL7n7K5l19MkxM7PbSkJEz/nC6JfjZ2b3JV3zJ0//vdH6maFfwjOztyVd7dIPA/nuQ/YPgzaOWRoyprKdKUnuXknXX+r6QRxa+l2/ruR6iKyp9Hmxn36h74L5XOc/nlJ/Pyv0SRCta4dkZgvpd7yDfonmi5Jum9mV1gIzezVdTr9ENKjvPnT/EPiO39Q+62eOpRUnjLtfa/3QZHxe0oN0eT/9Qt8NWHoR+td6rKZPjllaSWi9vizpnqQpM7uRWUe/RODJALOrkm6Y2f007N3MnLWgX+IZ1HcftH8IfDiR0l9eVyS9st+2CCPtg6kuQRzxtKp5U+5+y90raaC4LenLEduFxB1J19LX1yV9LmJb8D5D4Isk+z9pRPGGpM90ls776Rf6bmA+5x3T4nRDnxyrVvjuvPzhjqTLHRVA+uUYpdXwBXd/3d2f126170bHdvRLJIP67kP1D4Hv+LX+QW0rzWY6+PHxNufkSedRuu7t8yj10y/03YCk16LsN68UfXLMMv8BqnQsb71/QfRLLFezA2nS1x+R9Ln054l+iWdQ333Q/mHi5WPm7otm1u2asZl0/ROTOWJw0gueb3cOEui3X+i7gZmX9KJZ26CzBSXXi12XdNfdb9EnUex1TesiPyvHL63u3e1cnvbFF5XMMcrPSySD/JkI2T9U+OK4o91rZVrmtQnkJfwAAAQgSURBVH/FA0eQXoTeNmN5ZmSU1F+/0HcDkF4fdi37kPRVJYNormVO9dInx++mkkrejlYFKVMBpF+O16KSO2t0U9HuKXj6JZ5Bfffh+ueoE/nxONTEjd0mNmWm87Df+YKSQRrzmcclJbdX67tf6LugfdRt4mX65Pj7YUqZu2pkvs/snTfol+Pvlye+u7SvrtMvx9oPvSZeHsh3H7J/mHg5krREP6/kf2bz4l6GwbQmreyxetHdP5LZdt9+oe8GK62wXlVy55MZJdO03PDdUxz0yTHL9MkjJZWlu/7kfafpl2OWTsUyq6RfpKTq2nkvXfplwNLfIa8p+a4uS3qgpOLWdnnQoL77UP1D4AMAACg4ruEDAAAoOAIfAABAwRH4AAAACo7ABwAAUHAEPgAAgIIj8AEAABQcgQ8Aciq9E8xtM2P+LABHwjx8AJBjrYnD3d323RgAeiDwAUDOmZkT+AAcBad0AQAACo7ABwAAUHBDsRsAAHljZlckPU7fvijphrsvmtklSV9WckPz5yQtZLa56+63uuyrdSP0x5Jm1P1m6ZfSfS2m29xz9wcd20ztdTwzuyypkr6dkvSSpGvuXhGAE49r+AAgw8xelSR3fz2z7G1Jz7t7xczmJb0t6ZWOwHVb0hvufjOz7LKkF939Wsf+K63t0kB4zd1f6vjcnVZYS0fpvpQNitnr+tJ9qGP9DRH4AKQIfACQ6jUiNg1P9zMh7YlBFGmV7r6k6UxQW5L0XGfoyi5Pw+TVjrD2tpKwdqt1PCWB80HHNq+4+4MeIbUtNAI42TilCwC7FiRVWhWzjBlJz+/1wTR4SdILku6k+3jcI3AtSlowsweS5jtP8aojAGY+08stSffN7CVJbygJek+cXgZwchH4AGDXjJKQ1hm2Ot/3sqjkej2lz3tV1+Z7rehyfO1VqUuvL3xO0hVJVyXdMLOb7n61r1YDKDxG6QLArtagicOa124lblHJ4Im9jrVX1a5vZnbJ3Svu/rq7Py9pWtJ8eloXAAh8ANDSqqylAzPadDnN27n+kpLBGK3q3D1JM+l1gdntpiRdUnLa9YGSU8iXuuyvZwWwi89nt0+rgdeUjOYFAAIfAHT4gqTr2QVp2FvsWNZZPbueflZSW+h6rWO719Q+erbb8boFwL2qhUqPlTUv6fY+nwFwQjBKFwA6pAHvJUl3lVyHt+jui5n1LukjSkLVlJJK2u1u196l+7qk3dPFjzsHVHQcT+nxHqRVu+uSLisZmPHFdD/XlVyvdyd9Pa+koti6bnBKkhi4AaCFwAcAB8S9bQG833BKFwAAoOAIfABwAH1cSwcAuUPgA4A+Ze6lKzN744AjaQEgGq7hAwAAKDgqfAAAAAVH4AMAACg4Ah8AAEDBEfgAAAAKjsAHAABQcAQ+AACAgvv/e7Wy/GJvCucAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.title(r'NN', fontsize = 30)\n",
    "plt.xlabel(r'epochs', fontsize=20)\n",
    "plt.ylabel(r'loss', fontsize=20)\n",
    "plt.yscale(\"log\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.grid(axis='both', alpha=.3)\n",
    "#plt.savefig(\"loss_Henon_E01667\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([[rd.randrange(-10, 10, 1)*0.001, rd.randrange(-10, 10, 1)*0.001] for _ in range(10)])\n",
    "\n",
    "f_iterations = [model(x0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    f_iterations.append(model(f_iterations[-1]))\n",
    "\n",
    "b_iterations = [f_iterations[-1]*np.array([[1., -1.]])]\n",
    "\n",
    "for _ in range(100):\n",
    "    b_iterations.append(model(b_iterations[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.title(r'SympNet', fontsize = 25)\n",
    "\n",
    "\n",
    "plt.scatter(*zip(*f_iterations[0].numpy()), s=5, linewidth=0, color='r', label= r'$\\hat{\\mathcal{T}}^{n}[X_{0}] \\qquad n=1,\\dots ,100$')\n",
    "\n",
    "for i in f_iterations:\n",
    "    plt.scatter(*zip(*i.numpy()), s=1, linewidth=0, color='r')\n",
    "    \n",
    "#plt.scatter(*zip(*f_iterations[-1].numpy()), s=15, linewidth=0, color='r')\n",
    "\n",
    "#plt.scatter(*zip(*b_iterations[0].numpy()), s=15, linewidth=0, color='b')\n",
    "\n",
    "b_iterations_symm = b_iterations*np.array([[1., -1.]])\n",
    "\n",
    "plt.scatter(*zip(*b_iterations_symm[0]), s=1, linewidth=0, color='b', label= r'$R \\hat{\\mathcal{T}}^{n}[R(\\hat{\\mathcal{T}}^{100}(X_{0}))] \\qquad n=1,\\dots 100$')\n",
    "\n",
    "for i in b_iterations_symm:\n",
    "    plt.scatter(*zip(*i), s=1, linewidth=0, color='b')\n",
    "\n",
    "plt.xlabel(r'$x$', fontsize=28, labelpad=8)\n",
    "plt.ylabel(r'$y$', fontsize=28, labelpad=15)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.grid(axis='both', alpha=.3)\n",
    "lgnd = plt.legend(scatterpoints=1, fontsize=25)\n",
    "lgnd.legendHandles[0]._sizes = [30]\n",
    "lgnd.legendHandles[1]._sizes = [30]\n",
    "#plt.savefig(\"Testing_Reversinility_NonReversible.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(199999, 2), dtype=float32, numpy=\n",
       "array([[-0.27259114, -0.38740158],\n",
       "       [-0.38889554, -0.32649854],\n",
       "       [ 0.616287  , -0.4700811 ],\n",
       "       ...,\n",
       "       [-0.39688355,  0.05138659],\n",
       "       [ 0.20687857,  0.11112433],\n",
       "       [ 0.609458  , -0.410024  ]], dtype=float32)>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_train)-y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(199999, 2), dtype=float32, numpy=\n",
       "array([[-0.33719853,  1.497931  ],\n",
       "       [-0.5441138 ,  0.99969405],\n",
       "       [ 0.48407993, -0.4089085 ],\n",
       "       ...,\n",
       "       [ 0.33482814, -0.49535787],\n",
       "       [ 1.9436991 , -1.3487009 ],\n",
       "       [ 0.83315367, -0.8523264 ]], dtype=float32)>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_train)-y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
